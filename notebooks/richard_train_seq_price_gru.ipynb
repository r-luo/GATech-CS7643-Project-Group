{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "619802ef-8335-4789-b02c-7740569430b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "%run _common.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459f259a-334e-426f-bf39-a844be16b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import model_data as md\n",
    "from matplotlib import pylab as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58ef9b59-f331-49d4-8b59-6c5fb03e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = md.MultiTickerPipeline(\n",
    "    target=\"price\",\n",
    "    target_type=\"sequence\",\n",
    "    model_seq_len=30,\n",
    "    max_overlap=20,\n",
    "    train_periods=[\n",
    "        (\"2012-01-01\", \"2019-12-31\"),\n",
    "    ],\n",
    "    test_periods=[\n",
    "        (\"2020-01-01\", \"2021-04-01\"),\n",
    "    ],\n",
    "    normalization_method=\"log\",\n",
    "    cross_validation_folds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a781c662-af1b-4563-a9ee-2d7afbc10d21",
   "metadata": {
    "tags": []
   },
   "source": [
    "pipeline.prepare_data([\"_all_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8df57c8f-f3df-4890-906f-ee43de77db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_data:Loading generated data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/price-sequence-96tickers...\n",
      "INFO:src.model_data:  Loading train folds...\n",
      "INFO:src.model_data:  Loading test arrays...\n"
     ]
    }
   ],
   "source": [
    "pipeline.load_data('price-sequence-96tickers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eed1a257-5979-48e1-a8ec-accce8c71339",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pipeline._train_out\n",
    "test_data = pipeline._test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f9d19b-c180-4c7f-af17-54f4c45c68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold5 = train_data[4]\n",
    "train = fold5['train']\n",
    "valid = fold5['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91eb7948-3393-4c1f-b7f4-a620f8c6f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc3a5fb-7e34-43aa-8340-2a1588d68cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train = torch.from_numpy(train['x']).to(device), torch.from_numpy(train['y']).to(device)\n",
    "x_valid, y_valid = torch.from_numpy(valid['x'].astype(\"float32\")).to(device), torch.from_numpy(valid['y'].astype(\"float32\")).to(device)\n",
    "x_test, y_test = torch.from_numpy(test_data['x'].astype(\"float32\")).to(device), torch.from_numpy(test_data['y'].astype(\"float32\")).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c31da20-39e8-4f8d-aeb6-23c01ecf5dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, datadict):\n",
    "        self.x = datadict['x'].astype(\"float32\")\n",
    "        self.y = datadict['y'].astype(\"float32\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4cc02a7-0291-408a-a470-0add20447e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        #\n",
    "        self.lstm = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().to(device)\n",
    "        out, (hn) = self.lstm(x, (h0.detach()))\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc31b71-2b73-4e2f-ba58-59a653767009",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_valid.shape[2]\n",
    "output_dim = y_valid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc718aa3-6b21-4e12-95bc-bae3ce5cc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_epochs = 400\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62ac5bc-1eb7-4132-b905-330b8c683e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_params = {\n",
    "    \"batch_size\": 64,\n",
    "    \"shuffle\": True,\n",
    "    \"num_workers\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f39817e-a0c2-4ddc-aed8-c4b644d7e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SeqDataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2298b6-9dd5-4890-b823-08b1b828c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, **data_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6331ec1-f64d-4df1-94bb-bb1d23c2c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SeqModel(input_dim, hidden_dim, num_layers, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab7b0804-330f-424f-b2ce-aa1ecfbf121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89a046d-ca12-4619-9661-1950d70128b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69da9fc0-d6f1-43a8-a611-47a31b0cd5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 400\n",
    "early_stopping_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01922543-2e2d-4afb-97c8-62cf0d0c0052",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 78.51, validation loss: 142.66, last day valid loss: 143.74\n",
      "Epoch 1, train loss: 64.48, validation loss: 126.17, last day valid loss: 127.19\n",
      "Epoch 2, train loss: 51.38, validation loss: 112.27, last day valid loss: 113.28\n",
      "Epoch 3, train loss: 45.66, validation loss: 103.31, last day valid loss: 104.28\n",
      "Epoch 4, train loss: 41.61, validation loss: 96.75, last day valid loss: 97.70\n",
      "Epoch 5, train loss: 38.86, validation loss: 91.48, last day valid loss: 92.33\n",
      "Epoch 6, train loss: 37.28, validation loss: 86.87, last day valid loss: 87.62\n",
      "Epoch 7, train loss: 34.88, validation loss: 83.11, last day valid loss: 83.83\n",
      "Epoch 8, train loss: 33.29, validation loss: 79.59, last day valid loss: 80.28\n",
      "Epoch 9, train loss: 31.98, validation loss: 76.77, last day valid loss: 77.42\n",
      "Epoch 10, train loss: 30.99, validation loss: 73.74, last day valid loss: 74.40\n",
      "Epoch 11, train loss: 30.05, validation loss: 71.46, last day valid loss: 72.05\n",
      "Epoch 12, train loss: 29.63, validation loss: 69.29, last day valid loss: 69.90\n",
      "Epoch 13, train loss: 28.25, validation loss: 67.33, last day valid loss: 67.88\n",
      "Epoch 14, train loss: 27.50, validation loss: 65.68, last day valid loss: 66.16\n",
      "Epoch 15, train loss: 26.80, validation loss: 64.27, last day valid loss: 64.74\n",
      "Epoch 16, train loss: 26.29, validation loss: 62.71, last day valid loss: 63.14\n",
      "Epoch 17, train loss: 25.56, validation loss: 61.19, last day valid loss: 61.68\n",
      "Epoch 18, train loss: 25.02, validation loss: 59.62, last day valid loss: 60.08\n",
      "Epoch 19, train loss: 24.54, validation loss: 58.53, last day valid loss: 58.99\n",
      "Epoch 20, train loss: 23.95, validation loss: 57.29, last day valid loss: 57.65\n",
      "Epoch 21, train loss: 23.43, validation loss: 56.01, last day valid loss: 56.38\n",
      "Epoch 22, train loss: 22.89, validation loss: 54.99, last day valid loss: 55.32\n",
      "Epoch 23, train loss: 22.49, validation loss: 54.08, last day valid loss: 54.44\n",
      "Epoch 24, train loss: 22.29, validation loss: 53.12, last day valid loss: 53.43\n",
      "Epoch 25, train loss: 21.80, validation loss: 52.47, last day valid loss: 52.87\n",
      "Epoch 26, train loss: 21.32, validation loss: 52.00, last day valid loss: 52.34\n",
      "Epoch 27, train loss: 20.98, validation loss: 50.79, last day valid loss: 51.13\n",
      "Epoch 28, train loss: 20.72, validation loss: 51.02, last day valid loss: 51.28\n",
      "Epoch 29, train loss: 20.59, validation loss: 49.52, last day valid loss: 49.77\n",
      "Epoch 30, train loss: 20.10, validation loss: 48.94, last day valid loss: 49.23\n",
      "Epoch 31, train loss: 19.76, validation loss: 48.48, last day valid loss: 48.84\n",
      "Epoch 32, train loss: 19.53, validation loss: 47.56, last day valid loss: 47.86\n",
      "Epoch 33, train loss: 19.33, validation loss: 47.24, last day valid loss: 47.56\n",
      "Epoch 34, train loss: 18.99, validation loss: 46.68, last day valid loss: 46.95\n",
      "Epoch 35, train loss: 18.77, validation loss: 46.32, last day valid loss: 46.57\n",
      "Epoch 36, train loss: 18.49, validation loss: 45.82, last day valid loss: 46.11\n",
      "Epoch 37, train loss: 18.17, validation loss: 45.83, last day valid loss: 46.20\n",
      "Epoch 38, train loss: 18.03, validation loss: 44.98, last day valid loss: 45.26\n",
      "Epoch 39, train loss: 17.93, validation loss: 44.48, last day valid loss: 44.71\n",
      "Epoch 40, train loss: 17.65, validation loss: 45.47, last day valid loss: 45.85\n",
      "Epoch 41, train loss: 17.42, validation loss: 43.80, last day valid loss: 43.99\n",
      "Epoch 42, train loss: 17.35, validation loss: 43.71, last day valid loss: 43.92\n",
      "Epoch 43, train loss: 17.09, validation loss: 43.29, last day valid loss: 43.49\n",
      "Epoch 44, train loss: 16.88, validation loss: 42.97, last day valid loss: 43.15\n",
      "Epoch 45, train loss: 16.67, validation loss: 42.92, last day valid loss: 43.07\n",
      "Epoch 46, train loss: 16.47, validation loss: 42.85, last day valid loss: 43.04\n",
      "Epoch 47, train loss: 16.31, validation loss: 42.00, last day valid loss: 42.21\n",
      "Epoch 48, train loss: 16.18, validation loss: 42.11, last day valid loss: 42.24\n",
      "Epoch 49, train loss: 16.01, validation loss: 41.28, last day valid loss: 41.40\n",
      "Epoch 50, train loss: 15.76, validation loss: 41.01, last day valid loss: 41.10\n",
      "Epoch 51, train loss: 15.54, validation loss: 41.34, last day valid loss: 41.42\n",
      "Epoch 52, train loss: 15.53, validation loss: 40.54, last day valid loss: 40.64\n",
      "Epoch 53, train loss: 15.35, validation loss: 40.05, last day valid loss: 40.12\n",
      "Epoch 54, train loss: 15.15, validation loss: 40.37, last day valid loss: 40.37\n",
      "Epoch 55, train loss: 15.01, validation loss: 39.44, last day valid loss: 39.51\n",
      "Epoch 56, train loss: 14.79, validation loss: 39.46, last day valid loss: 39.51\n",
      "Epoch 57, train loss: 14.65, validation loss: 39.34, last day valid loss: 39.55\n",
      "Epoch 58, train loss: 14.50, validation loss: 38.54, last day valid loss: 38.61\n",
      "Epoch 59, train loss: 14.39, validation loss: 38.57, last day valid loss: 38.69\n",
      "Epoch 60, train loss: 14.19, validation loss: 38.24, last day valid loss: 38.33\n",
      "Epoch 61, train loss: 14.11, validation loss: 38.09, last day valid loss: 38.21\n",
      "Epoch 62, train loss: 14.11, validation loss: 37.80, last day valid loss: 37.85\n",
      "Epoch 63, train loss: 13.67, validation loss: 38.20, last day valid loss: 38.37\n",
      "Epoch 64, train loss: 13.59, validation loss: 37.29, last day valid loss: 37.40\n",
      "Epoch 65, train loss: 13.50, validation loss: 36.97, last day valid loss: 36.97\n",
      "Epoch 66, train loss: 13.32, validation loss: 37.09, last day valid loss: 37.18\n",
      "Epoch 67, train loss: 13.21, validation loss: 36.69, last day valid loss: 36.76\n",
      "Epoch 68, train loss: 13.27, validation loss: 36.70, last day valid loss: 36.87\n",
      "Epoch 69, train loss: 12.89, validation loss: 36.35, last day valid loss: 36.47\n",
      "Epoch 70, train loss: 12.90, validation loss: 37.47, last day valid loss: 37.55\n",
      "Epoch 71, train loss: 12.68, validation loss: 35.86, last day valid loss: 35.89\n",
      "Epoch 72, train loss: 12.75, validation loss: 36.02, last day valid loss: 35.98\n",
      "Epoch 73, train loss: 12.40, validation loss: 35.55, last day valid loss: 35.63\n",
      "Epoch 74, train loss: 12.33, validation loss: 35.34, last day valid loss: 35.41\n",
      "Epoch 75, train loss: 12.32, validation loss: 35.38, last day valid loss: 35.40\n",
      "Epoch 76, train loss: 12.19, validation loss: 34.83, last day valid loss: 34.89\n",
      "Epoch 77, train loss: 11.95, validation loss: 34.88, last day valid loss: 34.93\n",
      "Epoch 78, train loss: 12.01, validation loss: 34.43, last day valid loss: 34.51\n",
      "Epoch 79, train loss: 11.70, validation loss: 34.19, last day valid loss: 34.28\n",
      "Epoch 80, train loss: 11.54, validation loss: 34.16, last day valid loss: 34.29\n",
      "Epoch 81, train loss: 11.48, validation loss: 34.36, last day valid loss: 34.40\n",
      "Epoch 82, train loss: 11.36, validation loss: 33.66, last day valid loss: 33.74\n",
      "Epoch 83, train loss: 11.43, validation loss: 33.97, last day valid loss: 34.10\n",
      "Epoch 84, train loss: 11.22, validation loss: 33.57, last day valid loss: 33.69\n",
      "Epoch 85, train loss: 11.33, validation loss: 33.39, last day valid loss: 33.49\n",
      "Epoch 86, train loss: 10.93, validation loss: 33.27, last day valid loss: 33.31\n",
      "Epoch 87, train loss: 10.90, validation loss: 33.28, last day valid loss: 33.46\n",
      "Epoch 88, train loss: 10.79, validation loss: 32.91, last day valid loss: 32.91\n",
      "Epoch 89, train loss: 10.76, validation loss: 33.77, last day valid loss: 34.04\n",
      "Epoch 90, train loss: 10.64, validation loss: 32.74, last day valid loss: 32.77\n",
      "Epoch 91, train loss: 10.61, validation loss: 32.37, last day valid loss: 32.39\n",
      "Epoch 92, train loss: 10.40, validation loss: 32.28, last day valid loss: 32.34\n",
      "Epoch 93, train loss: 10.27, validation loss: 32.51, last day valid loss: 32.50\n",
      "Epoch 94, train loss: 10.37, validation loss: 32.00, last day valid loss: 32.14\n",
      "Epoch 95, train loss: 10.15, validation loss: 31.61, last day valid loss: 31.70\n",
      "Epoch 96, train loss: 10.01, validation loss: 31.64, last day valid loss: 31.84\n",
      "Epoch 97, train loss: 9.93, validation loss: 31.39, last day valid loss: 31.42\n",
      "Epoch 98, train loss: 9.97, validation loss: 31.05, last day valid loss: 31.14\n",
      "Epoch 99, train loss: 9.86, validation loss: 31.18, last day valid loss: 31.25\n",
      "Epoch 100, train loss: 9.64, validation loss: 30.69, last day valid loss: 30.77\n",
      "Epoch 101, train loss: 9.82, validation loss: 30.55, last day valid loss: 30.63\n",
      "Epoch 102, train loss: 9.45, validation loss: 30.52, last day valid loss: 30.61\n",
      "Epoch 103, train loss: 9.38, validation loss: 30.44, last day valid loss: 30.42\n",
      "Epoch 104, train loss: 9.43, validation loss: 30.05, last day valid loss: 30.19\n",
      "Epoch 105, train loss: 9.24, validation loss: 29.93, last day valid loss: 30.04\n",
      "Epoch 106, train loss: 9.48, validation loss: 29.85, last day valid loss: 29.94\n",
      "Epoch 107, train loss: 9.18, validation loss: 29.99, last day valid loss: 30.03\n",
      "Epoch 108, train loss: 9.06, validation loss: 29.73, last day valid loss: 29.85\n",
      "Epoch 109, train loss: 9.24, validation loss: 29.62, last day valid loss: 29.75\n",
      "Epoch 110, train loss: 9.35, validation loss: 30.23, last day valid loss: 30.22\n",
      "Epoch 111, train loss: 8.87, validation loss: 30.41, last day valid loss: 30.52\n",
      "Epoch 112, train loss: 8.80, validation loss: 28.89, last day valid loss: 28.95\n",
      "Epoch 113, train loss: 8.74, validation loss: 28.90, last day valid loss: 28.99\n",
      "Epoch 114, train loss: 8.71, validation loss: 28.73, last day valid loss: 28.78\n",
      "Epoch 115, train loss: 8.82, validation loss: 29.32, last day valid loss: 29.30\n",
      "Epoch 116, train loss: 8.46, validation loss: 28.17, last day valid loss: 28.23\n",
      "Epoch 117, train loss: 8.38, validation loss: 28.87, last day valid loss: 28.94\n",
      "Epoch 118, train loss: 8.36, validation loss: 28.09, last day valid loss: 28.11\n",
      "Epoch 119, train loss: 8.37, validation loss: 28.16, last day valid loss: 28.24\n",
      "Epoch 120, train loss: 8.30, validation loss: 27.86, last day valid loss: 27.88\n",
      "Epoch 121, train loss: 8.34, validation loss: 27.56, last day valid loss: 27.55\n",
      "Epoch 122, train loss: 8.06, validation loss: 27.71, last day valid loss: 27.79\n",
      "Epoch 123, train loss: 8.08, validation loss: 27.63, last day valid loss: 27.72\n",
      "Epoch 124, train loss: 7.87, validation loss: 27.32, last day valid loss: 27.37\n",
      "Epoch 125, train loss: 7.98, validation loss: 28.12, last day valid loss: 28.29\n",
      "Epoch 126, train loss: 8.00, validation loss: 27.80, last day valid loss: 28.02\n",
      "Epoch 127, train loss: 7.97, validation loss: 26.89, last day valid loss: 26.98\n",
      "Epoch 128, train loss: 7.78, validation loss: 27.19, last day valid loss: 27.24\n",
      "Epoch 129, train loss: 7.70, validation loss: 26.41, last day valid loss: 26.52\n",
      "Epoch 130, train loss: 7.56, validation loss: 27.26, last day valid loss: 27.25\n",
      "Epoch 131, train loss: 7.57, validation loss: 26.61, last day valid loss: 26.68\n",
      "Epoch 132, train loss: 7.56, validation loss: 26.51, last day valid loss: 26.62\n",
      "Epoch 133, train loss: 7.47, validation loss: 26.87, last day valid loss: 27.01\n",
      "Epoch 134, train loss: 7.39, validation loss: 25.68, last day valid loss: 25.77\n",
      "Epoch 135, train loss: 7.40, validation loss: 25.82, last day valid loss: 25.81\n",
      "Epoch 136, train loss: 7.24, validation loss: 25.93, last day valid loss: 26.04\n",
      "Epoch 137, train loss: 7.53, validation loss: 25.39, last day valid loss: 25.45\n",
      "Epoch 138, train loss: 7.13, validation loss: 24.90, last day valid loss: 24.90\n",
      "Epoch 139, train loss: 6.99, validation loss: 25.27, last day valid loss: 25.29\n",
      "Epoch 140, train loss: 6.95, validation loss: 25.30, last day valid loss: 25.46\n",
      "Epoch 141, train loss: 7.28, validation loss: 24.69, last day valid loss: 24.73\n",
      "Epoch 142, train loss: 6.91, validation loss: 25.19, last day valid loss: 25.24\n",
      "Epoch 143, train loss: 6.93, validation loss: 24.17, last day valid loss: 24.24\n",
      "Epoch 144, train loss: 6.66, validation loss: 25.09, last day valid loss: 25.34\n",
      "Epoch 145, train loss: 6.69, validation loss: 24.01, last day valid loss: 24.06\n",
      "Epoch 146, train loss: 6.61, validation loss: 23.88, last day valid loss: 23.93\n",
      "Epoch 147, train loss: 6.57, validation loss: 24.05, last day valid loss: 24.11\n",
      "Epoch 148, train loss: 6.55, validation loss: 23.83, last day valid loss: 23.85\n",
      "Epoch 149, train loss: 6.56, validation loss: 23.82, last day valid loss: 23.86\n",
      "Epoch 150, train loss: 6.42, validation loss: 23.49, last day valid loss: 23.57\n",
      "Epoch 151, train loss: 6.47, validation loss: 23.48, last day valid loss: 23.55\n",
      "Epoch 152, train loss: 6.31, validation loss: 23.79, last day valid loss: 23.98\n",
      "Epoch 153, train loss: 6.28, validation loss: 23.27, last day valid loss: 23.29\n",
      "Epoch 154, train loss: 6.17, validation loss: 24.33, last day valid loss: 24.59\n",
      "Epoch 155, train loss: 6.20, validation loss: 23.12, last day valid loss: 23.08\n",
      "Epoch 156, train loss: 6.16, validation loss: 22.92, last day valid loss: 22.91\n",
      "Epoch 157, train loss: 6.21, validation loss: 22.48, last day valid loss: 22.41\n",
      "Epoch 158, train loss: 6.15, validation loss: 22.18, last day valid loss: 22.21\n",
      "Epoch 159, train loss: 6.27, validation loss: 22.37, last day valid loss: 22.42\n",
      "Epoch 160, train loss: 5.97, validation loss: 22.00, last day valid loss: 22.05\n",
      "Epoch 161, train loss: 5.97, validation loss: 22.12, last day valid loss: 22.14\n",
      "Epoch 162, train loss: 5.78, validation loss: 21.92, last day valid loss: 21.91\n",
      "Epoch 163, train loss: 6.06, validation loss: 21.92, last day valid loss: 21.84\n",
      "Epoch 164, train loss: 5.78, validation loss: 21.95, last day valid loss: 22.05\n",
      "Epoch 165, train loss: 5.88, validation loss: 21.63, last day valid loss: 21.69\n",
      "Epoch 166, train loss: 5.72, validation loss: 21.64, last day valid loss: 21.73\n",
      "Epoch 167, train loss: 5.75, validation loss: 21.28, last day valid loss: 21.40\n",
      "Epoch 168, train loss: 5.57, validation loss: 21.00, last day valid loss: 21.11\n",
      "Epoch 169, train loss: 5.56, validation loss: 21.13, last day valid loss: 21.24\n",
      "Epoch 170, train loss: 5.64, validation loss: 22.12, last day valid loss: 22.25\n",
      "Epoch 171, train loss: 5.50, validation loss: 20.67, last day valid loss: 20.70\n",
      "Epoch 172, train loss: 5.49, validation loss: 21.03, last day valid loss: 21.11\n",
      "Epoch 173, train loss: 5.56, validation loss: 20.97, last day valid loss: 21.06\n",
      "Epoch 174, train loss: 5.33, validation loss: 20.42, last day valid loss: 20.53\n",
      "Epoch 175, train loss: 5.33, validation loss: 20.51, last day valid loss: 20.55\n",
      "Epoch 176, train loss: 5.26, validation loss: 20.09, last day valid loss: 20.14\n",
      "Epoch 177, train loss: 5.32, validation loss: 20.60, last day valid loss: 20.65\n",
      "Epoch 178, train loss: 5.24, validation loss: 19.83, last day valid loss: 19.92\n",
      "Epoch 179, train loss: 5.20, validation loss: 19.79, last day valid loss: 19.84\n",
      "Epoch 180, train loss: 5.10, validation loss: 19.85, last day valid loss: 19.91\n",
      "Epoch 181, train loss: 5.16, validation loss: 19.44, last day valid loss: 19.44\n",
      "Epoch 182, train loss: 5.03, validation loss: 19.75, last day valid loss: 19.87\n",
      "Epoch 183, train loss: 5.00, validation loss: 19.32, last day valid loss: 19.34\n",
      "Epoch 184, train loss: 4.96, validation loss: 19.64, last day valid loss: 19.74\n",
      "Epoch 185, train loss: 4.95, validation loss: 19.69, last day valid loss: 19.72\n",
      "Epoch 186, train loss: 5.04, validation loss: 19.16, last day valid loss: 19.32\n",
      "Epoch 187, train loss: 5.09, validation loss: 19.24, last day valid loss: 19.26\n",
      "Epoch 188, train loss: 4.86, validation loss: 18.83, last day valid loss: 18.93\n",
      "Epoch 189, train loss: 4.77, validation loss: 18.82, last day valid loss: 18.86\n",
      "Epoch 190, train loss: 4.82, validation loss: 19.64, last day valid loss: 19.72\n",
      "Epoch 191, train loss: 5.06, validation loss: 18.59, last day valid loss: 18.75\n",
      "Epoch 192, train loss: 4.82, validation loss: 19.10, last day valid loss: 19.16\n",
      "Epoch 193, train loss: 4.70, validation loss: 18.48, last day valid loss: 18.50\n",
      "Epoch 194, train loss: 4.71, validation loss: 18.80, last day valid loss: 18.82\n",
      "Epoch 195, train loss: 4.66, validation loss: 17.84, last day valid loss: 17.86\n",
      "Epoch 196, train loss: 4.61, validation loss: 18.11, last day valid loss: 18.18\n",
      "Epoch 197, train loss: 4.52, validation loss: 18.18, last day valid loss: 18.38\n",
      "Epoch 198, train loss: 4.55, validation loss: 17.85, last day valid loss: 17.97\n",
      "Epoch 199, train loss: 4.49, validation loss: 17.99, last day valid loss: 18.09\n",
      "Epoch 200, train loss: 4.54, validation loss: 18.06, last day valid loss: 18.22\n",
      "Epoch 201, train loss: 4.56, validation loss: 17.61, last day valid loss: 17.65\n",
      "Epoch 202, train loss: 4.53, validation loss: 18.60, last day valid loss: 18.79\n",
      "Epoch 203, train loss: 4.46, validation loss: 18.00, last day valid loss: 18.16\n",
      "Epoch 204, train loss: 4.42, validation loss: 17.49, last day valid loss: 17.53\n",
      "Epoch 205, train loss: 4.33, validation loss: 17.75, last day valid loss: 17.82\n",
      "Epoch 206, train loss: 4.39, validation loss: 17.49, last day valid loss: 17.56\n",
      "Epoch 207, train loss: 4.43, validation loss: 17.10, last day valid loss: 17.19\n",
      "Epoch 208, train loss: 4.34, validation loss: 17.02, last day valid loss: 17.10\n",
      "Epoch 209, train loss: 4.24, validation loss: 16.75, last day valid loss: 16.78\n",
      "Epoch 210, train loss: 4.39, validation loss: 16.90, last day valid loss: 16.91\n",
      "Epoch 211, train loss: 4.15, validation loss: 16.65, last day valid loss: 16.73\n",
      "Epoch 212, train loss: 4.14, validation loss: 16.54, last day valid loss: 16.63\n",
      "Epoch 213, train loss: 4.13, validation loss: 16.47, last day valid loss: 16.53\n",
      "Epoch 214, train loss: 4.08, validation loss: 16.38, last day valid loss: 16.43\n",
      "Epoch 215, train loss: 4.30, validation loss: 16.49, last day valid loss: 16.57\n",
      "Epoch 216, train loss: 4.16, validation loss: 17.02, last day valid loss: 17.15\n",
      "Epoch 217, train loss: 4.30, validation loss: 16.65, last day valid loss: 16.76\n",
      "Epoch 218, train loss: 4.06, validation loss: 16.62, last day valid loss: 16.78\n",
      "Epoch 219, train loss: 4.08, validation loss: 16.06, last day valid loss: 16.06\n",
      "Epoch 220, train loss: 4.05, validation loss: 17.03, last day valid loss: 17.37\n",
      "Epoch 221, train loss: 4.08, validation loss: 16.24, last day valid loss: 16.40\n",
      "Epoch 222, train loss: 4.03, validation loss: 16.11, last day valid loss: 16.14\n",
      "Epoch 223, train loss: 4.00, validation loss: 15.86, last day valid loss: 15.89\n",
      "Epoch 224, train loss: 4.08, validation loss: 15.79, last day valid loss: 15.86\n",
      "Epoch 225, train loss: 3.85, validation loss: 15.72, last day valid loss: 15.74\n",
      "Epoch 226, train loss: 4.32, validation loss: 16.04, last day valid loss: 16.08\n",
      "Epoch 227, train loss: 4.11, validation loss: 15.97, last day valid loss: 16.17\n",
      "Epoch 228, train loss: 3.94, validation loss: 15.95, last day valid loss: 16.11\n",
      "Epoch 229, train loss: 3.95, validation loss: 16.50, last day valid loss: 16.74\n",
      "Epoch 230, train loss: 3.94, validation loss: 15.58, last day valid loss: 15.62\n",
      "Epoch 231, train loss: 3.89, validation loss: 15.76, last day valid loss: 15.97\n",
      "Epoch 232, train loss: 3.80, validation loss: 15.17, last day valid loss: 15.37\n",
      "Epoch 233, train loss: 3.77, validation loss: 15.67, last day valid loss: 15.79\n",
      "Epoch 234, train loss: 3.83, validation loss: 15.32, last day valid loss: 15.41\n",
      "Epoch 235, train loss: 3.97, validation loss: 15.20, last day valid loss: 15.26\n",
      "Epoch 236, train loss: 3.70, validation loss: 15.17, last day valid loss: 15.23\n",
      "Epoch 237, train loss: 3.79, validation loss: 15.34, last day valid loss: 15.54\n",
      "Epoch 238, train loss: 3.73, validation loss: 15.15, last day valid loss: 15.24\n",
      "Epoch 239, train loss: 3.87, validation loss: 15.30, last day valid loss: 15.37\n",
      "Epoch 240, train loss: 3.78, validation loss: 14.65, last day valid loss: 14.75\n",
      "Epoch 241, train loss: 3.74, validation loss: 15.20, last day valid loss: 15.34\n",
      "Epoch 242, train loss: 3.68, validation loss: 14.64, last day valid loss: 14.70\n",
      "Epoch 243, train loss: 3.51, validation loss: 14.67, last day valid loss: 14.74\n",
      "Epoch 244, train loss: 3.62, validation loss: 14.68, last day valid loss: 14.84\n",
      "Epoch 245, train loss: 3.73, validation loss: 14.98, last day valid loss: 15.20\n",
      "Epoch 246, train loss: 3.70, validation loss: 14.57, last day valid loss: 14.68\n",
      "Epoch 247, train loss: 3.60, validation loss: 14.41, last day valid loss: 14.54\n",
      "Epoch 248, train loss: 3.58, validation loss: 14.48, last day valid loss: 14.45\n",
      "Epoch 249, train loss: 3.53, validation loss: 14.57, last day valid loss: 14.81\n",
      "Epoch 250, train loss: 3.55, validation loss: 14.62, last day valid loss: 14.84\n",
      "Epoch 251, train loss: 3.46, validation loss: 14.38, last day valid loss: 14.41\n",
      "Epoch 252, train loss: 3.50, validation loss: 15.80, last day valid loss: 16.09\n",
      "Epoch 253, train loss: 3.70, validation loss: 14.20, last day valid loss: 14.27\n",
      "Epoch 254, train loss: 3.65, validation loss: 14.08, last day valid loss: 14.24\n",
      "Epoch 255, train loss: 3.46, validation loss: 14.08, last day valid loss: 14.24\n",
      "Epoch 256, train loss: 3.43, validation loss: 14.59, last day valid loss: 14.65\n",
      "Epoch 257, train loss: 3.37, validation loss: 14.19, last day valid loss: 14.24\n",
      "Epoch 258, train loss: 3.47, validation loss: 14.45, last day valid loss: 14.52\n",
      "Epoch 259, train loss: 3.45, validation loss: 13.80, last day valid loss: 13.80\n",
      "Epoch 260, train loss: 3.44, validation loss: 14.09, last day valid loss: 14.24\n",
      "Epoch 261, train loss: 3.44, validation loss: 14.16, last day valid loss: 14.33\n",
      "Epoch 262, train loss: 3.41, validation loss: 15.71, last day valid loss: 15.87\n",
      "Epoch 263, train loss: 3.49, validation loss: 13.64, last day valid loss: 13.68\n",
      "Epoch 264, train loss: 3.42, validation loss: 13.73, last day valid loss: 13.91\n",
      "Epoch 265, train loss: 3.47, validation loss: 13.76, last day valid loss: 13.90\n",
      "Epoch 266, train loss: 3.49, validation loss: 13.98, last day valid loss: 13.99\n",
      "Epoch 267, train loss: 3.43, validation loss: 13.80, last day valid loss: 13.88\n",
      "Epoch 268, train loss: 3.45, validation loss: 14.06, last day valid loss: 14.40\n",
      "Epoch 269, train loss: 3.41, validation loss: 13.79, last day valid loss: 13.69\n",
      "Epoch 270, train loss: 3.36, validation loss: 13.33, last day valid loss: 13.38\n",
      "Epoch 271, train loss: 3.38, validation loss: 13.93, last day valid loss: 14.13\n",
      "Epoch 272, train loss: 3.33, validation loss: 13.37, last day valid loss: 13.44\n",
      "Epoch 273, train loss: 3.39, validation loss: 13.65, last day valid loss: 13.60\n",
      "Epoch 274, train loss: 3.33, validation loss: 13.14, last day valid loss: 13.15\n",
      "Epoch 275, train loss: 3.28, validation loss: 12.99, last day valid loss: 13.00\n",
      "Epoch 276, train loss: 3.36, validation loss: 13.03, last day valid loss: 12.98\n",
      "Epoch 277, train loss: 3.23, validation loss: 13.12, last day valid loss: 13.18\n",
      "Epoch 278, train loss: 3.35, validation loss: 12.95, last day valid loss: 13.13\n",
      "Epoch 279, train loss: 3.34, validation loss: 13.07, last day valid loss: 13.08\n",
      "Epoch 280, train loss: 3.27, validation loss: 12.59, last day valid loss: 12.69\n",
      "Epoch 281, train loss: 3.15, validation loss: 12.49, last day valid loss: 12.56\n",
      "Epoch 282, train loss: 3.19, validation loss: 12.96, last day valid loss: 13.13\n",
      "Epoch 283, train loss: 3.21, validation loss: 12.71, last day valid loss: 12.80\n",
      "Epoch 284, train loss: 3.28, validation loss: 12.98, last day valid loss: 13.02\n",
      "Epoch 285, train loss: 3.18, validation loss: 13.02, last day valid loss: 13.09\n",
      "Epoch 286, train loss: 3.17, validation loss: 13.10, last day valid loss: 13.12\n",
      "Epoch 287, train loss: 3.23, validation loss: 12.65, last day valid loss: 12.90\n",
      "Epoch 288, train loss: 3.29, validation loss: 13.25, last day valid loss: 13.41\n",
      "Epoch 289, train loss: 3.35, validation loss: 12.56, last day valid loss: 12.57\n",
      "Epoch 290, train loss: 3.12, validation loss: 12.60, last day valid loss: 12.64\n",
      "Epoch 291, train loss: 3.14, validation loss: 12.48, last day valid loss: 12.67\n",
      "Epoch 292, train loss: 3.14, validation loss: 13.32, last day valid loss: 13.45\n",
      "Epoch 293, train loss: 3.21, validation loss: 12.66, last day valid loss: 12.66\n",
      "Epoch 294, train loss: 3.07, validation loss: 12.64, last day valid loss: 12.85\n",
      "Epoch 295, train loss: 3.07, validation loss: 12.52, last day valid loss: 12.53\n",
      "Epoch 296, train loss: 3.17, validation loss: 12.28, last day valid loss: 12.37\n",
      "Epoch 297, train loss: 3.17, validation loss: 11.84, last day valid loss: 11.91\n",
      "Epoch 298, train loss: 3.05, validation loss: 12.07, last day valid loss: 12.20\n",
      "Epoch 299, train loss: 3.06, validation loss: 12.61, last day valid loss: 12.69\n",
      "Epoch 300, train loss: 3.09, validation loss: 11.86, last day valid loss: 12.05\n",
      "Epoch 301, train loss: 3.15, validation loss: 11.97, last day valid loss: 12.00\n",
      "Epoch 302, train loss: 3.20, validation loss: 11.83, last day valid loss: 11.91\n",
      "Epoch 303, train loss: 3.01, validation loss: 12.99, last day valid loss: 13.36\n",
      "Epoch 304, train loss: 3.01, validation loss: 11.86, last day valid loss: 11.92\n",
      "Epoch 305, train loss: 3.09, validation loss: 11.98, last day valid loss: 12.01\n",
      "Epoch 306, train loss: 3.06, validation loss: 12.02, last day valid loss: 12.09\n",
      "Epoch 307, train loss: 3.09, validation loss: 11.87, last day valid loss: 12.07\n",
      "Epoch 308, train loss: 3.00, validation loss: 12.31, last day valid loss: 12.56\n",
      "Epoch 309, train loss: 3.02, validation loss: 12.33, last day valid loss: 12.42\n",
      "Epoch 310, train loss: 3.12, validation loss: 11.63, last day valid loss: 11.78\n",
      "Epoch 311, train loss: 3.11, validation loss: 11.70, last day valid loss: 11.75\n",
      "Epoch 312, train loss: 2.99, validation loss: 11.27, last day valid loss: 11.26\n",
      "Epoch 313, train loss: 2.93, validation loss: 11.67, last day valid loss: 11.93\n",
      "Epoch 314, train loss: 2.98, validation loss: 11.18, last day valid loss: 11.26\n",
      "Epoch 315, train loss: 2.85, validation loss: 11.23, last day valid loss: 11.37\n",
      "Epoch 316, train loss: 2.84, validation loss: 11.19, last day valid loss: 11.19\n",
      "Epoch 317, train loss: 2.87, validation loss: 11.43, last day valid loss: 11.48\n",
      "Epoch 318, train loss: 2.88, validation loss: 11.22, last day valid loss: 11.34\n",
      "Epoch 319, train loss: 3.02, validation loss: 11.23, last day valid loss: 11.36\n",
      "Epoch 320, train loss: 2.86, validation loss: 11.07, last day valid loss: 11.27\n",
      "Epoch 321, train loss: 2.85, validation loss: 10.84, last day valid loss: 10.96\n",
      "Epoch 322, train loss: 2.81, validation loss: 11.19, last day valid loss: 11.26\n",
      "Epoch 323, train loss: 2.95, validation loss: 11.12, last day valid loss: 11.11\n",
      "Epoch 324, train loss: 2.87, validation loss: 11.34, last day valid loss: 11.48\n",
      "Epoch 325, train loss: 2.94, validation loss: 10.91, last day valid loss: 11.00\n",
      "Epoch 326, train loss: 2.95, validation loss: 11.16, last day valid loss: 11.34\n",
      "Epoch 327, train loss: 2.75, validation loss: 10.89, last day valid loss: 10.95\n",
      "Epoch 328, train loss: 2.82, validation loss: 11.42, last day valid loss: 11.42\n",
      "Epoch 329, train loss: 2.71, validation loss: 10.95, last day valid loss: 10.98\n",
      "Epoch 330, train loss: 2.78, validation loss: 10.51, last day valid loss: 10.57\n",
      "Epoch 331, train loss: 2.85, validation loss: 10.93, last day valid loss: 10.99\n",
      "Epoch 332, train loss: 2.73, validation loss: 10.82, last day valid loss: 10.89\n",
      "Epoch 333, train loss: 2.96, validation loss: 11.21, last day valid loss: 11.34\n",
      "Epoch 334, train loss: 2.90, validation loss: 10.22, last day valid loss: 10.25\n",
      "Epoch 335, train loss: 2.83, validation loss: 10.58, last day valid loss: 10.71\n",
      "Epoch 336, train loss: 2.71, validation loss: 10.25, last day valid loss: 10.33\n",
      "Epoch 337, train loss: 2.78, validation loss: 10.18, last day valid loss: 10.21\n",
      "Epoch 338, train loss: 2.64, validation loss: 10.36, last day valid loss: 10.37\n",
      "Epoch 339, train loss: 2.70, validation loss: 10.89, last day valid loss: 11.07\n",
      "Epoch 340, train loss: 2.91, validation loss: 10.69, last day valid loss: 10.69\n",
      "Epoch 341, train loss: 2.86, validation loss: 10.02, last day valid loss: 10.14\n",
      "Epoch 342, train loss: 2.73, validation loss: 10.07, last day valid loss: 10.14\n",
      "Epoch 343, train loss: 2.61, validation loss: 10.31, last day valid loss: 10.38\n",
      "Epoch 344, train loss: 2.73, validation loss: 10.07, last day valid loss: 10.06\n",
      "Epoch 345, train loss: 2.79, validation loss: 9.95, last day valid loss: 10.00\n",
      "Epoch 346, train loss: 2.60, validation loss: 10.28, last day valid loss: 10.44\n",
      "Epoch 347, train loss: 2.74, validation loss: 10.15, last day valid loss: 10.12\n",
      "Epoch 348, train loss: 2.74, validation loss: 10.25, last day valid loss: 10.49\n",
      "Epoch 349, train loss: 2.73, validation loss: 9.77, last day valid loss: 9.92\n",
      "Epoch 350, train loss: 2.68, validation loss: 10.62, last day valid loss: 10.83\n",
      "Epoch 351, train loss: 2.71, validation loss: 9.71, last day valid loss: 9.74\n",
      "Epoch 352, train loss: 2.70, validation loss: 10.47, last day valid loss: 10.73\n",
      "Epoch 353, train loss: 2.63, validation loss: 9.61, last day valid loss: 9.66\n",
      "Epoch 354, train loss: 2.61, validation loss: 9.59, last day valid loss: 9.66\n",
      "Epoch 355, train loss: 2.73, validation loss: 9.64, last day valid loss: 9.63\n",
      "Epoch 356, train loss: 2.62, validation loss: 9.43, last day valid loss: 9.36\n",
      "Epoch 357, train loss: 2.55, validation loss: 9.51, last day valid loss: 9.59\n",
      "Epoch 358, train loss: 2.67, validation loss: 9.65, last day valid loss: 9.79\n",
      "Epoch 359, train loss: 2.67, validation loss: 9.35, last day valid loss: 9.39\n",
      "Epoch 360, train loss: 2.77, validation loss: 9.37, last day valid loss: 9.44\n",
      "Epoch 361, train loss: 2.56, validation loss: 9.13, last day valid loss: 9.17\n",
      "Epoch 362, train loss: 2.56, validation loss: 9.87, last day valid loss: 9.83\n",
      "Epoch 363, train loss: 2.60, validation loss: 9.16, last day valid loss: 9.19\n",
      "Epoch 364, train loss: 2.58, validation loss: 9.43, last day valid loss: 9.30\n",
      "Epoch 365, train loss: 2.59, validation loss: 9.48, last day valid loss: 9.63\n",
      "Epoch 366, train loss: 2.51, validation loss: 9.37, last day valid loss: 9.43\n",
      "Epoch 367, train loss: 2.55, validation loss: 9.21, last day valid loss: 9.30\n",
      "Epoch 368, train loss: 2.49, validation loss: 9.21, last day valid loss: 9.29\n",
      "Epoch 369, train loss: 2.61, validation loss: 9.87, last day valid loss: 10.04\n",
      "Epoch 370, train loss: 2.63, validation loss: 9.84, last day valid loss: 9.90\n",
      "Epoch 371, train loss: 2.61, validation loss: 9.46, last day valid loss: 9.60\n",
      "Validation loss not improved in the last 10 epochs, breaking...\n",
      "test loss: 24.42, last day test loss: 25.76\n"
     ]
    }
   ],
   "source": [
    "train_hist = []\n",
    "valid_hist = []\n",
    "min_observed_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_per_batch = []\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        model.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_per_batch.append(loss.item())\n",
    "        del x, y\n",
    "        torch.cuda.empty_cache()\n",
    "    train_loss_epoch = np.mean(train_loss_per_batch)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_valid_pred = model(x_valid)\n",
    "        valid_loss_epoch = criterion(y_valid_pred, y_valid)\n",
    "\n",
    "        # last-day loss\n",
    "        last_loss_valid = criterion(y_valid_pred[:, -1, :], y_valid[:, -1, :])\n",
    "\n",
    "        del y_valid_pred\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    min_observed_valid_loss = min(min_observed_valid_loss, valid_loss_epoch)\n",
    "    \n",
    "    train_hist.append(train_loss_epoch)\n",
    "    valid_hist.append(valid_loss_epoch)\n",
    "    \n",
    "    print(f\"Epoch {epoch}, train loss: {train_loss_epoch:.2f}, validation loss: {valid_loss_epoch:.2f}, last day valid loss: {last_loss_valid:.2f}\")\n",
    "    \n",
    "    if epoch > early_stopping_epochs:\n",
    "        if min_observed_valid_loss < min(valid_hist[-10:]):\n",
    "            print(f\"Validation loss not improved in the last {early_stopping_epochs} epochs, breaking...\")\n",
    "            break\n",
    "\n",
    "y_test_pred = model(x_test)\n",
    "test_loss = criterion(y_test_pred, y_test)\n",
    "last_loss_test = criterion(y_test_pred[:, -1, :], y_test[:, -1, :])\n",
    "print(f\"test loss: {test_loss:.2f}, last day test loss: {last_loss_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e6b7e-e58e-42f8-b3e5-d5026e9d8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03df5558-19ec-4737-ba07-7f12dc2bd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_ind = np.argwhere(test_data['ticker'] == ticker).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba284be7-9f7b-4f06-b0b2-6a3350daba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_ypred = y_test_pred.cpu().detach().numpy()[ticker_ind, -1, :]\n",
    "ticker_y = y_test.cpu().detach().numpy()[ticker_ind, -1, :]\n",
    "ticker_dates = test_data['prediction_date'][ticker_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "513b0b92-949c-44a5-8e56-542787a0eb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f438026c820>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(pd.to_datetime(ticker_dates), ticker_y)\n",
    "ax.plot(pd.to_datetime(ticker_dates), ticker_ypred, color=\"C2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87fade3b-ab6b-455a-8d5e-b037b677f56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30, 53])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e7518070-aaf6-4bc4-8132-ee19e5907dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfb65646-77c0-489e-af72-57713702443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 30, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ef01b-eeb8-44a4-99e4-1b2f3ebf29b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
