{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a91596-6193-46a1-b7ed-f2eda9d5a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1f8691-1441-4cfd-ab0f-e2682f4b2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\".\").absolute().parent.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6a1e47-3860-4bf9-875a-a24415bb1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import model_data as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f6ce3a-7635-4209-9ff7-9c5d33085f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        target: str\n",
      "            target can be \"price\", \"return\" or \"log_return\"\n",
      "        target_type: str\n",
      "            target type can be \"single\" for single point-in-time prediction \n",
      "            or \"sequence\" for sequence prediction (predicts a sequence of target shifted one day into the future)\n",
      "            if single, output y shape is (N, 1)\n",
      "            if sequence, output y shape is (N, model_seq_len, 1)\n",
      "        model_seq_len: int\n",
      "            model sequence length specifies the sequence length of each input sample. \n",
      "            E.g. 30 means using the past 30 days's historical data to predict the next day\n",
      "        max_overlap: int\n",
      "            maximum number of overlapping days between two sequences. Will be capped at model_seq_len - 1\n",
      "            if it is larger than model_seq_len\n",
      "        train_periods: list(tuple(str, str))\n",
      "            training periods is a list of tuples, each tuple has a start date and an end date. \n",
      "            Data from all training periods are put together\n",
      "            Note that training periods will be further divided into time series cross validation\n",
      "        test_periods: list(tuple(str, str))\n",
      "            similar to training periods\n",
      "        normalization_method: str\n",
      "            how features are normalized within each sequence\n",
      "            None: no normalization performed\n",
      "            \"log\": feature x is transformed into sign(x) * log(1 + |x|)\n",
      "            \"quantile\": feature x is transformed into (x - P50) / (P75 - P25), where P25, P50 and P75 are \n",
      "                the 25th, 50th and 75th quantile of x in the past lookback_period records (if available)\n",
      "        lookback_period: int\n",
      "            number of records from the past used to estimate quantiles, only used if normalization_method is set to \"quantile\"\n",
      "        cross_validation_folds: int\n",
      "            number of folds for rolling cross validation\n",
      "        data_path: str or pathlib.Path\n",
      "            path to the input data directory. Default: project_root/data/feature_selected\n",
      "        output_path: str or pathlib.Path\n",
      "            root path to store the output data. Default: project_root/data/model_data\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(md.SingleTickerPipeline.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cb7fed-a6f5-4425-9b62-b15ce22f1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ticker_pipeline = md.SingleTickerPipeline(\n",
    "    target=\"price\",\n",
    "    target_type=\"single\",\n",
    "    model_seq_len=30,\n",
    "    max_overlap=20,\n",
    "    train_periods=[\n",
    "        (\"2000-01-01\", \"2006-12-31\"),\n",
    "        (\"2009-01-01\", \"2018-12-31\"),\n",
    "    ],\n",
    "    test_periods=[\n",
    "        (\"2007-01-01\", \"2008-12-31\"),\n",
    "        (\"2019-01-01\", \"2021-04-01\"),\n",
    "    ],\n",
    "    normalization_method=\"log\",\n",
    "#     lookback_period=200,\n",
    "    cross_validation_folds=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab11293-46f5-43ac-a6a4-e298c752f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_data:Reading data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/feature_selected/TEAM.csv...\n",
      "INFO:src.model_data:Making training arrays...\n",
      "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "INFO:src.model_data:  Training has 73 sequences of length 30.\n",
      "INFO:src.model_data:Making 5 validation folds...\n",
      "INFO:src.model_data:  Generating folds with fold_size=11 and distance between train and validation being 3\n",
      "INFO:src.model_data:    Fold 0 shapes:\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 1 shapes:\n",
      "INFO:src.model_data:      x: (22, 30, 53), y: (22, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 2 shapes:\n",
      "INFO:src.model_data:      x: (33, 30, 53), y: (33, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 3 shapes:\n",
      "INFO:src.model_data:      x: (44, 30, 53), y: (44, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 4 shapes:\n",
      "INFO:src.model_data:      x: (55, 30, 53), y: (55, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 53), y: (11, 1)\n",
      "INFO:src.model_data:Making testing arrays...\n",
      "INFO:src.model_data:  Training has 537 sequences of length 30.\n",
      "INFO:src.model_data:Saving generated data at /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:src.model_data:  Writing train folds...\n",
      "INFO:src.model_data:  Writing test arrays...\n"
     ]
    }
   ],
   "source": [
    "single_ticker_pipeline.prepare_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48963822-cd45-4cf2-af6a-a5783c6841b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_data:Loading generated data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:src.model_data:  Loading train folds...\n",
      "INFO:src.model_data:  Loading test arrays...\n"
     ]
    }
   ],
   "source": [
    "# If loading existing data:\n",
    "single_ticker_pipeline.load_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3560fa-08d0-4b5f-ba0b-9e2b6080994d",
   "metadata": {},
   "source": [
    "### Train dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3253eadb-5e55-44c0-9872-c4b6e10df33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(22, 30, 53)\",\n",
      "            \"y\": \"(22, 1)\",\n",
      "            \"target_date\": \"(22, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(33, 30, 53)\",\n",
      "            \"y\": \"(33, 1)\",\n",
      "            \"target_date\": \"(33, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(44, 30, 53)\",\n",
      "            \"y\": \"(44, 1)\",\n",
      "            \"target_date\": \"(44, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(55, 30, 53)\",\n",
      "            \"y\": \"(55, 1)\",\n",
      "            \"target_date\": \"(55, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 1)\",\n",
      "            \"target_date\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"_all_\": {\n",
      "        \"x\": \"(73, 30, 53)\",\n",
      "        \"y\": \"(73, 1)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "single_ticker_pipeline.print_train_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c5e82-7684-4a1d-b1cf-f8226e336cd6",
   "metadata": {},
   "source": [
    "### Test dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f7a171f-0aff-473c-908a-6e5b1973d45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"N\": 537,\n",
      "    \"target_date\": \"(537, 1)\",\n",
      "    \"x\": \"(537, 30, 53)\",\n",
      "    \"y\": \"(537, 1)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "single_ticker_pipeline.print_test_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b0962-96d6-48af-9ded-fccfdc9f7676",
   "metadata": {},
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22be205-1303-4861-85b1-2eb106b88d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed539f-4774-4ff2-b177-37598b948551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ae2517-3f52-44cc-8f23-a695050d8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = Path(\"./create_training_data.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14cca2-4496-42d8-9d29-806cb1462a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc885e4-0473-4671-8ff6-96443438ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(__file__).absolute().parent.parent.joinpath(\"data/feature_selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b333a106-a604-45c1-b6f5-9bfc1b1eca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/feature_selected')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae2dd93-5cfa-4404-aab2-18811dc30ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = list(data_path.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbc5d0-9fa4-4790-8569-91d72c64550b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4de1e901-d29c-43bc-9f7a-563d5acadd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target can be \"price\", \"return\" or \"log_return\"\n",
    "target = \"price\"\n",
    "\n",
    "# target type can be single prediction or sequence prediction\n",
    "target_type = \"sequence\"\n",
    "\n",
    "# model sequence length specifies the sequence length of each input sample. E.g. 30 means using the past 30 days's historical data to predict the next day\n",
    "model_seq_len = 30\n",
    "\n",
    "# maximum number of overlapping days of historical data between two records\n",
    "max_overlap = 20\n",
    "\n",
    "# training periods is a list of tuples, each tuple has a start date and an end date. Data from all training periods are put together\n",
    "# Note that training periods will be further divided into training and valiation, or time series cross validation\n",
    "train_periods = [\n",
    "    (\"2000-01-01\", \"2006-12-31\"),\n",
    "    (\"2010-01-01\", \"2018-12-31\")\n",
    "]\n",
    "\n",
    "# testing periods - similar to training periods\n",
    "test_periods = [\n",
    "    (\"2007-01-01\", \"2009-12-31\"),\n",
    "    (\"2019-01-01\", \"2021-04-01\")\n",
    "]\n",
    "\n",
    "cross_validation_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38ec48-6d84-4249-af02-e0972e260407",
   "metadata": {},
   "source": [
    "## Single Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "988f1883-a10e-4753-80a0-271437658c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__ = \"create_training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae030e6-6c90-4da3-846a-06ba0d7d2e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fcc48883a28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSingleTickerPipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     def __init__(\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-fcc48883a28a>\u001b[0m in \u001b[0;36mSingleTickerPipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlookback_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcross_validation_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/feature_selected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moutput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/model_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     ):\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class SingleTickerPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target=\"price\",\n",
    "        target_type=\"sequence\",\n",
    "        model_seq_len=30,\n",
    "        max_overlap=20,\n",
    "        train_periods=[\n",
    "            (\"2000-01-01\", \"2006-12-31\"),\n",
    "            (\"2009-01-01\", \"2018-12-31\"),\n",
    "        ],\n",
    "        test_periods=[\n",
    "            (\"2007-01-01\", \"2008-12-31\"),\n",
    "            (\"2019-01-01\", \"2021-04-01\"),\n",
    "        ],\n",
    "        normalization_method=\"log\",\n",
    "        lookback_period=200,\n",
    "        cross_validation_folds=5,\n",
    "        data_path=Path(__file__).absolute().parent.parent.joinpath(\"data/feature_selected\"),\n",
    "        output_path=Path(__file__).absolute().parent.parent.joinpath(\"data/model_data\"),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        target: str\n",
    "            target can be \"price\", \"return\" or \"log_return\"\n",
    "        target_type: str\n",
    "            target type can be \"single\" for single point-in-time prediction \n",
    "            or \"sequence\" for sequence prediction (predicts a sequence of target shifted one day into the future)\n",
    "            if single, output y shape is (N, 1)\n",
    "            if sequence, output y shape is (N, model_seq_len, 1)\n",
    "        model_seq_len: int\n",
    "            model sequence length specifies the sequence length of each input sample. \n",
    "            E.g. 30 means using the past 30 days's historical data to predict the next day\n",
    "        max_overlap: int\n",
    "            maximum number of overlapping days between two sequences. Will be capped at model_seq_len - 1\n",
    "            if it is larger than model_seq_len\n",
    "        train_periods: list(tuple(str, str))\n",
    "            training periods is a list of tuples, each tuple has a start date and an end date. \n",
    "            Data from all training periods are put together\n",
    "            Note that training periods will be further divided into time series cross validation\n",
    "        test_periods: list(tuple(str, str))\n",
    "            similar to training periods\n",
    "        normalization_method: str\n",
    "            how features are normalized within each sequence\n",
    "            None: no normalization performed\n",
    "            \"log\": feature x is transformed into sign(x) * log(1 + |x|)\n",
    "            \"quantile\": feature x is transformed into (x - P50) / (P75 - P25), where P25, P50 and P75 are \n",
    "                the 25th, 50th and 75th quantile of x in the past lookback_period records (if available)\n",
    "        lookback_period: int\n",
    "            number of records from the past used to estimate quantiles, only used if normalization_method is set to \"quantile\"\n",
    "        cross_validation_folds: int\n",
    "            number of folds for rolling cross validation\n",
    "        data_path: str or pathlib.Path\n",
    "            path to the input data directory. Default: project_root/data/feature_selected\n",
    "        output_path: str or pathlib.Path\n",
    "            root path to store the output data. Default: project_root/data/model_data\n",
    "        \"\"\"\n",
    "        self.target = target\n",
    "        self.target_col = \"adj_close\" if target == 'price' else target\n",
    "        self.target_type = target_type\n",
    "        self.model_seq_len = model_seq_len\n",
    "        self.max_overlap = min(model_seq_len - 1, max_overlap)\n",
    "        self.train_periods = train_periods\n",
    "        self.test_periods = test_periods\n",
    "        self.normalization_method = normalization_method\n",
    "        self.lookback_period = lookback_period\n",
    "        self.cross_validation_folds = cross_validation_folds\n",
    "        self.data_path = Path(data_path)\n",
    "        self.output_path = Path(output_path)\n",
    "        \n",
    "        # internal attributes\n",
    "        self._df = None\n",
    "        self._ticker = None\n",
    "        self._feature_cols = None\n",
    "        self._train_out = None\n",
    "        self._test_out = None\n",
    "        self._seq_dist = self.model_seq_len - self.max_overlap\n",
    "        self._save_path = None\n",
    "        \n",
    "    def load_input(self, ticker=None):\n",
    "        ticker = ticker or self._ticker\n",
    "        data_file = self.data_path.joinpath(f\"{ticker}.csv\")\n",
    "        LOG.info(f\"Reading data from {data_file.as_posix()}...\")\n",
    "        df = pd.read_csv(data_file).drop('price', axis=1, errors=\"ignore\").sort_values(\"date\", ascending=True)\n",
    "        if self.target == \"price\":\n",
    "            df.loc[:, \"target\"] = df['adj_close']\n",
    "        else: \n",
    "            if self.target == \"return\":\n",
    "                return_col = get_return_col(df, log=False)\n",
    "            if self.target == \"log_return\":\n",
    "                return_col = get_return_col(df, log=True)\n",
    "            df.loc[:, \"target\"] = df[return_col]\n",
    "            df.drop(['adj_close'])\n",
    "        self._feature_cols = df.drop(['date', 'target'], axis=1).columns.tolist()\n",
    "        \n",
    "        # match the target with data from the previous days\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                df[['target', 'date']].rename({'date': 'target_date'}, axis=1).iloc[1:, :].reset_index(drop=True),\n",
    "                df[self._feature_cols + [\"date\"]].iloc[:-1, :].reset_index(drop=True)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        self._df = df\n",
    "\n",
    "    def get_xy_arr(self, dfs, seq_dist=None):\n",
    "        seq_dist = seq_dist or self._seq_dist\n",
    "        arrays = {\"x\": [], \"y\": [], \"target_date\": [], \"N\": 0}\n",
    "        for df in dfs:\n",
    "            N = df.shape[0]\n",
    "            if N >= self.model_seq_len:\n",
    "                for i in range((N - self.model_seq_len) // seq_dist):\n",
    "                    feature_subdf = df[self._feature_cols].iloc[(N - (i * seq_dist + self.model_seq_len)):(N - i * seq_dist)]\n",
    "                    target_col_copy = feature_subdf[[self.target_col]]\n",
    "                    if self.normalization_method == \"quantile\":\n",
    "                        feature_quantiles = df[self._feature_cols].iloc[\n",
    "                            max(0, (N - (i * seq_dist + self.lookback_period))):(N - i * seq_dist)\n",
    "                        ].quantile([0.25, 0.5, 0.75])\n",
    "                        p25 = feature_quantiles.loc[0.25, :]\n",
    "                        p50 = feature_quantiles.loc[0.50, :]\n",
    "                        p75 = feature_quantiles.loc[0.75, :]\n",
    "                        feature_subdf = ((feature_subdf - p50) / (p75 - p25))\n",
    "                    elif self.normalization_method == \"log\":\n",
    "                        feature_subdf = np.sign(feature_subdf) * np.log1p(np.abs(feature_subdf))\n",
    "                    \n",
    "                    feature_subdf = pd.concat([target_col_copy, feature_subdf], axis=1).replace([-np.inf, np.inf], np.nan).fillna(0)\n",
    "                    arrays[\"x\"].append(feature_subdf.values)\n",
    "                    if self.target_type == \"sequence\":\n",
    "                        arrays[\"y\"].append(df[[\"target\"]].iloc[(N - (i * seq_dist + self.model_seq_len)):(N - i * seq_dist)].values)\n",
    "                        arrays[\"target_date\"].append(df[[\"target_date\"]].iloc[(N - (i * seq_dist + self.model_seq_len)):(N - i * seq_dist)].values)\n",
    "                    elif self.target_type == \"single\":\n",
    "                        arrays[\"y\"].append([df[\"target\"].iloc[(N - i * seq_dist) - 1]])\n",
    "                        arrays[\"target_date\"].append([df[\"target_date\"].iloc[(N - i * seq_dist) - 1]])\n",
    "                    else:\n",
    "                        raise KeyError(\"Unknown target_type: target_type must be one of 'sequence' or 'single'!\")\n",
    "                    arrays[\"N\"] += 1\n",
    "        arrays[\"x\"] = np.array(arrays['x'][::-1])\n",
    "        arrays[\"y\"] = np.array(arrays['y'][::-1])\n",
    "        arrays[\"target_date\"] = np.array(arrays['target_date'][::-1])\n",
    "        return arrays\n",
    "\n",
    "    def create_train_array(self):\n",
    "        LOG.info(\"Making training arrays...\")\n",
    "        train_dfs = get_period_data(self._df, self.train_periods)\n",
    "        train_xy_arrs = self.get_xy_arr(train_dfs)\n",
    "        LOG.info(f\"  Training has {train_xy_arrs['N']} sequences of length {self.model_seq_len}.\")\n",
    "        \n",
    "        LOG.info(f\"Making {self.cross_validation_folds} validation folds...\")\n",
    "        train_val_distance = int(np.ceil(self.model_seq_len / self._seq_dist))\n",
    "        fold_size = (train_xy_arrs[\"N\"] - train_val_distance) // (self.cross_validation_folds + 1)\n",
    "        \n",
    "        LOG.info(f\"  Generating folds with fold_size={fold_size} and distance between train and validation being {train_val_distance}\")\n",
    "        folds = {}\n",
    "        for i in range(self.cross_validation_folds):\n",
    "            train_end_ind = fold_size * (i + 1)\n",
    "            val_begin_ind = fold_size * (i + 1) + train_val_distance\n",
    "            val_end_ind = val_begin_ind + fold_size\n",
    "            fold_arrs = {\n",
    "                \"train\":{\n",
    "                    \"x\": train_xy_arrs[\"x\"][:train_end_ind],\n",
    "                    \"y\": train_xy_arrs[\"y\"][:train_end_ind],\n",
    "                    \"target_date\": train_xy_arrs[\"target_date\"][:train_end_ind],\n",
    "                },\n",
    "                \"valid\":{\n",
    "                    \"x\": train_xy_arrs[\"x\"][val_begin_ind:val_end_ind],\n",
    "                    \"y\": train_xy_arrs[\"y\"][val_begin_ind:val_end_ind],\n",
    "                    \"target_date\": train_xy_arrs[\"target_date\"][val_begin_ind:val_end_ind],\n",
    "                },\n",
    "            }\n",
    "            folds[i] = fold_arrs\n",
    "            LOG.info(f\"    Fold {i} shapes:\")\n",
    "            for sample in fold_arrs:\n",
    "                LOG.info(f\"      x: {fold_arrs[sample]['x'].shape}, y: {fold_arrs[sample]['y'].shape}\")\n",
    "        folds[\"_all_\"] = {'x': train_xy_arrs['x'], 'y': train_xy_arrs['y']}\n",
    "        self._train_out = folds\n",
    "        \n",
    "    def create_test_array(self):\n",
    "        LOG.info(\"Making testing arrays...\")\n",
    "        test_dfs = get_period_data(self._df, self.test_periods)\n",
    "        test_xy_arrs = self.get_xy_arr(test_dfs, seq_dist=1)\n",
    "        LOG.info(f\"  Training has {test_xy_arrs['N']} sequences of length {self.model_seq_len}.\")\n",
    "        self._test_out = test_xy_arrs\n",
    "    \n",
    "    def create_arrays(self):\n",
    "        self.create_train_array()\n",
    "        self.create_test_array()\n",
    "        self._save_path = self.output_path.joinpath(self._ticker)\n",
    "        LOG.info(f\"Saving generated data at {self._save_path.as_posix()}...\")\n",
    "        if not self._save_path.exists():\n",
    "            LOG.info(f\"  Directory doesn't exist, making directory...\")\n",
    "            self._save_path.mkdir(parents=True)\n",
    "        LOG.info(\"  Writing train folds...\")\n",
    "        write_pickle_file(self._train_out, self._save_path.joinpath(\"train.pkl\"))\n",
    "        LOG.info(\"  Writing test arrays...\")\n",
    "        write_pickle_file(self._test_out, self._save_path.joinpath(\"test.pkl\"))\n",
    "        \n",
    "    def prepare_data(self, ticker):\n",
    "        self._ticker = ticker\n",
    "        self.load_input()\n",
    "        self.create_arrays()\n",
    "        \n",
    "    def load_data(self, ticker):\n",
    "        self._ticker = ticker\n",
    "        self._save_path = self.output_path.joinpath(self._ticker)\n",
    "        LOG.info(f\"Loading generated data from {self._save_path.as_posix()}...\")\n",
    "        if not self._save_path.exists():\n",
    "            raise FileNotFoundError(\"Directory doesn't exist, can't load data!\")\n",
    "        LOG.info(\"  Loading train folds...\")\n",
    "        self._train_out = load_pickle_file(self._save_path.joinpath(\"train.pkl\"))\n",
    "        LOG.info(\"  Loading test arrays...\")\n",
    "        self._test_out = load_pickle_file(self._save_path.joinpath(\"test.pkl\"))\n",
    "    \n",
    "    def print_train_shapes(self):\n",
    "        print(\n",
    "            json.dumps({\n",
    "                i: {\n",
    "                    s: ({k: str(v.shape) for k, v in arr.items()} if isinstance(arr, dict) else str(arr.shape)) \n",
    "                    for s, arr in fold.items()\n",
    "                } for i, fold in self._train_out.items()\n",
    "            }, sort_keys=False, indent=4)\n",
    "        )\n",
    "        \n",
    "    def print_test_shapes(self):\n",
    "        print(\n",
    "            json.dumps(\n",
    "                {k: str(v.shape) if hasattr(v, \"shape\") else v for k, v in self._test_out.items()},\n",
    "                sort_keys=True, indent=4\n",
    "            )\n",
    "        )\n",
    "    \n",
    "def get_return_col(df, log=False):\n",
    "    price_rat = df['adj_close'] / df['adj_close'].shift(-1)\n",
    "    if log:\n",
    "        return_col_name = \"log_return\"\n",
    "        return_col_value = np.log(price_rat)\n",
    "    else:\n",
    "        return_col_name = \"return\"\n",
    "        return_col_value = price_rat - 1\n",
    "    df.loc[:, return_col_name] = return_col_value\n",
    "    return return_col_name\n",
    "\n",
    "\n",
    "def get_period_data(df, periods, date_col=\"date\"):\n",
    "    dfs_by_period = [\n",
    "        df[\n",
    "            pd.to_datetime(df[date_col]).between(pd.to_datetime(period[0]), pd.to_datetime(period[1]))\n",
    "        ].sort_values(date_col, ascending=True) for period in periods\n",
    "    ]\n",
    "    return dfs_by_period\n",
    "\n",
    "\n",
    "def write_pickle_file(obj, file):\n",
    "    with Path(file).open('wb') as pkl_file:\n",
    "        pickle.dump(obj, pkl_file, protocol=4)\n",
    "\n",
    "\n",
    "def load_pickle_file(file):\n",
    "    with Path(file).open('rb') as pkl_file:\n",
    "        obj = pickle.load(pkl_file)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fcb04861-d3ae-4a57-aa87-d796a8c74e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = SingleTickerPipeline(normalization_method=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2385e35c-2710-4727-a3c2-be518247d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Reading data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/feature_selected/TEAM.csv...\n",
      "INFO:__main__:Making training arrays...\n",
      "INFO:__main__:  Training has 73 sequences of length 30.\n",
      "INFO:__main__:Making 5 validation folds...\n",
      "INFO:__main__:  Generating folds with fold_size=11 and distance between train and validation being 3\n",
      "INFO:__main__:    Fold 0 shapes:\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:    Fold 1 shapes:\n",
      "INFO:__main__:      x: (22, 30, 53), y: (22, 30, 1)\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:    Fold 2 shapes:\n",
      "INFO:__main__:      x: (33, 30, 53), y: (33, 30, 1)\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:    Fold 3 shapes:\n",
      "INFO:__main__:      x: (44, 30, 53), y: (44, 30, 1)\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:    Fold 4 shapes:\n",
      "INFO:__main__:      x: (55, 30, 53), y: (55, 30, 1)\n",
      "INFO:__main__:      x: (11, 30, 53), y: (11, 30, 1)\n",
      "INFO:__main__:Making testing arrays...\n",
      "INFO:__main__:  Training has 537 sequences of length 30.\n",
      "INFO:__main__:Saving generated data at /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:__main__:  Writing train folds...\n",
      "INFO:__main__:  Writing test arrays...\n"
     ]
    }
   ],
   "source": [
    "pipeline.prepare_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0f2bc-b5b2-4600-848a-2c1f1c329358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "938b92d9-9f1d-49e9-a000-93a80e5baf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(22, 30, 53)\",\n",
      "            \"y\": \"(22, 30, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(33, 30, 53)\",\n",
      "            \"y\": \"(33, 30, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(44, 30, 53)\",\n",
      "            \"y\": \"(44, 30, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(55, 30, 53)\",\n",
      "            \"y\": \"(55, 30, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 53)\",\n",
      "            \"y\": \"(11, 30, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"_all_\": {\n",
      "        \"x\": \"(73, 30, 53)\",\n",
      "        \"y\": \"(73, 30, 1)\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps({i: {s: ({k: str(v.shape) for k, v in arr.items()} if isinstance(arr, dict) else str(arr.shape)) for s, arr in fold.items()} for i, fold in pipeline._train_out.items()}, sort_keys=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a99f027-e07f-46da-aa55-cce57efa37c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading generated data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:__main__:  Loading train folds...\n",
      "INFO:__main__:  Loading test arrays...\n"
     ]
    }
   ],
   "source": [
    "pipeline.load_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85fc0bea-56a5-48e6-8a30-a78824403ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = get_period_data(pipeline._df, pipeline.train_periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a67ec-c284-4930-b0d9-ca45652537c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d1bf8bc-4bbb-4c61-b8f1-e404140268fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concat = pd.concat(train_dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f64a31d8-8a11-49d2-9ea8-3bce7e30c2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ev</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>pb</th>\n",
       "      <th>pe</th>\n",
       "      <th>evebit</th>\n",
       "      <th>retearn</th>\n",
       "      <th>accoci</th>\n",
       "      <th>ps</th>\n",
       "      <th>shareswa</th>\n",
       "      <th>...</th>\n",
       "      <th>revenueusd</th>\n",
       "      <th>revenue</th>\n",
       "      <th>divyield</th>\n",
       "      <th>sgna</th>\n",
       "      <th>cor</th>\n",
       "      <th>receivables</th>\n",
       "      <th>gp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>invcap</th>\n",
       "      <th>currentratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     adj_close   ev  marketcap   pb   pe  evebit  retearn  accoci   ps  \\\n",
       "0          1.0  1.0        1.0  1.0  1.0     1.0      1.0     0.0  1.0   \n",
       "1          1.0  1.0        1.0  1.0  1.0     1.0      1.0     0.0  1.0   \n",
       "2          1.0  1.0        1.0  1.0  1.0     1.0      1.0     0.0  1.0   \n",
       "3          1.0  1.0        1.0  1.0  1.0     1.0      1.0     0.0  1.0   \n",
       "4          1.0  1.0        1.0  1.0  1.0     1.0      1.0     0.0  1.0   \n",
       "..         ...  ...        ...  ...  ...     ...      ...     ...  ...   \n",
       "764        1.0  1.0        1.0  1.0 -1.0    -1.0     -1.0     0.0  1.0   \n",
       "765        1.0  1.0        1.0  1.0 -1.0    -1.0     -1.0     0.0  1.0   \n",
       "766        1.0  1.0        1.0  1.0 -1.0    -1.0     -1.0     0.0  1.0   \n",
       "767        1.0  1.0        1.0  1.0 -1.0    -1.0     -1.0     0.0  1.0   \n",
       "768        1.0  1.0        1.0  1.0 -1.0    -1.0     -1.0     0.0  1.0   \n",
       "\n",
       "     shareswa  ...  revenueusd  revenue  divyield  sgna  cor  receivables  \\\n",
       "0         1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "1         1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "2         1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "3         1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "4         1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "..        ...  ...         ...      ...       ...   ...  ...          ...   \n",
       "764       1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "765       1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "766       1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "767       1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "768       1.0  ...         1.0      1.0       0.0   1.0  1.0          1.0   \n",
       "\n",
       "      gp  taxliabilities  invcap  currentratio  \n",
       "0    1.0             1.0     1.0           1.0  \n",
       "1    1.0             1.0     1.0           1.0  \n",
       "2    1.0             1.0     1.0           1.0  \n",
       "3    1.0             1.0     1.0           1.0  \n",
       "4    1.0             1.0     1.0           1.0  \n",
       "..   ...             ...     ...           ...  \n",
       "764  1.0             1.0     1.0           1.0  \n",
       "765  1.0             1.0     1.0           1.0  \n",
       "766  1.0             1.0     1.0           1.0  \n",
       "767  1.0             1.0     1.0           1.0  \n",
       "768  1.0             1.0     1.0           1.0  \n",
       "\n",
       "[769 rows x 52 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(train_concat[pipeline._feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f38d851-1cc7-4fff-a9cc-0bb16b4a24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_describe = train_concat.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89f4efcc-5bfa-4b6b-9fe6-3cec2c89c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = train_concat[pipeline._feature_cols].agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be1f1b65-84ae-4bda-b190-171821fce4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ev</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>pb</th>\n",
       "      <th>pe</th>\n",
       "      <th>evebit</th>\n",
       "      <th>retearn</th>\n",
       "      <th>accoci</th>\n",
       "      <th>ps</th>\n",
       "      <th>shareswa</th>\n",
       "      <th>...</th>\n",
       "      <th>revenueusd</th>\n",
       "      <th>revenue</th>\n",
       "      <th>divyield</th>\n",
       "      <th>sgna</th>\n",
       "      <th>cor</th>\n",
       "      <th>receivables</th>\n",
       "      <th>gp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>invcap</th>\n",
       "      <th>currentratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.771824</td>\n",
       "      <td>-0.782292</td>\n",
       "      <td>-0.799935</td>\n",
       "      <td>2.209687</td>\n",
       "      <td>1.020279</td>\n",
       "      <td>1.992171</td>\n",
       "      <td>1.178283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294485</td>\n",
       "      <td>-2.947541</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737656</td>\n",
       "      <td>-1.433170</td>\n",
       "      <td>-0.727768</td>\n",
       "      <td>-1.782124</td>\n",
       "      <td>-1.273314</td>\n",
       "      <td>-1.749773</td>\n",
       "      <td>1.509293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.785770</td>\n",
       "      <td>-0.794417</td>\n",
       "      <td>-0.811850</td>\n",
       "      <td>2.178333</td>\n",
       "      <td>1.010464</td>\n",
       "      <td>1.971751</td>\n",
       "      <td>1.178283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232390</td>\n",
       "      <td>-2.947541</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737656</td>\n",
       "      <td>-1.433170</td>\n",
       "      <td>-0.727768</td>\n",
       "      <td>-1.782124</td>\n",
       "      <td>-1.273314</td>\n",
       "      <td>-1.749773</td>\n",
       "      <td>1.509293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.847530</td>\n",
       "      <td>-0.848147</td>\n",
       "      <td>-0.864652</td>\n",
       "      <td>1.990209</td>\n",
       "      <td>0.966577</td>\n",
       "      <td>1.881138</td>\n",
       "      <td>1.178283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>-2.947541</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737656</td>\n",
       "      <td>-1.433170</td>\n",
       "      <td>-0.727768</td>\n",
       "      <td>-1.782124</td>\n",
       "      <td>-1.273314</td>\n",
       "      <td>-1.749773</td>\n",
       "      <td>1.509293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.835576</td>\n",
       "      <td>-0.837746</td>\n",
       "      <td>-0.854430</td>\n",
       "      <td>2.021563</td>\n",
       "      <td>0.974990</td>\n",
       "      <td>1.898686</td>\n",
       "      <td>1.178283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046107</td>\n",
       "      <td>-2.947541</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737656</td>\n",
       "      <td>-1.433170</td>\n",
       "      <td>-0.727768</td>\n",
       "      <td>-1.782124</td>\n",
       "      <td>-1.273314</td>\n",
       "      <td>-1.749773</td>\n",
       "      <td>1.509293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.833584</td>\n",
       "      <td>-0.836022</td>\n",
       "      <td>-0.852737</td>\n",
       "      <td>2.021563</td>\n",
       "      <td>0.976392</td>\n",
       "      <td>1.901717</td>\n",
       "      <td>1.178283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077154</td>\n",
       "      <td>-2.947541</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>-1.689038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737656</td>\n",
       "      <td>-1.433170</td>\n",
       "      <td>-0.727768</td>\n",
       "      <td>-1.782124</td>\n",
       "      <td>-1.273314</td>\n",
       "      <td>-1.749773</td>\n",
       "      <td>1.509293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>1.762335</td>\n",
       "      <td>1.770585</td>\n",
       "      <td>1.807062</td>\n",
       "      <td>2.084271</td>\n",
       "      <td>-0.036935</td>\n",
       "      <td>-0.070557</td>\n",
       "      <td>-0.830421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.287999</td>\n",
       "      <td>0.518039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911815</td>\n",
       "      <td>0.912132</td>\n",
       "      <td>0.802412</td>\n",
       "      <td>0.844046</td>\n",
       "      <td>0.722499</td>\n",
       "      <td>-0.429552</td>\n",
       "      <td>-0.847556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2.094047</td>\n",
       "      <td>2.097117</td>\n",
       "      <td>2.127951</td>\n",
       "      <td>2.429166</td>\n",
       "      <td>-0.043244</td>\n",
       "      <td>-0.079810</td>\n",
       "      <td>-0.830421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.815803</td>\n",
       "      <td>0.518039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911815</td>\n",
       "      <td>0.912132</td>\n",
       "      <td>0.802412</td>\n",
       "      <td>0.844046</td>\n",
       "      <td>0.722499</td>\n",
       "      <td>-0.429552</td>\n",
       "      <td>-0.847556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>2.206112</td>\n",
       "      <td>2.207421</td>\n",
       "      <td>2.236349</td>\n",
       "      <td>2.554582</td>\n",
       "      <td>-0.045488</td>\n",
       "      <td>-0.083000</td>\n",
       "      <td>-0.830421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.971040</td>\n",
       "      <td>0.518039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911815</td>\n",
       "      <td>0.912132</td>\n",
       "      <td>0.802412</td>\n",
       "      <td>0.844046</td>\n",
       "      <td>0.722499</td>\n",
       "      <td>-0.429552</td>\n",
       "      <td>-0.847556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2.207606</td>\n",
       "      <td>2.208895</td>\n",
       "      <td>2.237798</td>\n",
       "      <td>2.554582</td>\n",
       "      <td>-0.045488</td>\n",
       "      <td>-0.083160</td>\n",
       "      <td>-0.830421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.971040</td>\n",
       "      <td>0.518039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>0.872251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.911815</td>\n",
       "      <td>0.912132</td>\n",
       "      <td>0.802412</td>\n",
       "      <td>0.844046</td>\n",
       "      <td>0.722499</td>\n",
       "      <td>-0.429552</td>\n",
       "      <td>-0.847556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>2.276339</td>\n",
       "      <td>2.276535</td>\n",
       "      <td>2.304269</td>\n",
       "      <td>2.632967</td>\n",
       "      <td>-0.046750</td>\n",
       "      <td>-0.085074</td>\n",
       "      <td>-13.397695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.095229</td>\n",
       "      <td>1.150426</td>\n",
       "      <td>...</td>\n",
       "      <td>5.812435</td>\n",
       "      <td>5.812435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.753872</td>\n",
       "      <td>2.572342</td>\n",
       "      <td>8.763506</td>\n",
       "      <td>7.179067</td>\n",
       "      <td>0.155970</td>\n",
       "      <td>6.630790</td>\n",
       "      <td>1.131844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     adj_close        ev  marketcap        pb        pe    evebit    retearn  \\\n",
       "0    -0.771824 -0.782292  -0.799935  2.209687  1.020279  1.992171   1.178283   \n",
       "1    -0.785770 -0.794417  -0.811850  2.178333  1.010464  1.971751   1.178283   \n",
       "2    -0.847530 -0.848147  -0.864652  1.990209  0.966577  1.881138   1.178283   \n",
       "3    -0.835576 -0.837746  -0.854430  2.021563  0.974990  1.898686   1.178283   \n",
       "4    -0.833584 -0.836022  -0.852737  2.021563  0.976392  1.901717   1.178283   \n",
       "..         ...       ...        ...       ...       ...       ...        ...   \n",
       "764   1.762335  1.770585   1.807062  2.084271 -0.036935 -0.070557  -0.830421   \n",
       "765   2.094047  2.097117   2.127951  2.429166 -0.043244 -0.079810  -0.830421   \n",
       "766   2.206112  2.207421   2.236349  2.554582 -0.045488 -0.083000  -0.830421   \n",
       "767   2.207606  2.208895   2.237798  2.554582 -0.045488 -0.083160  -0.830421   \n",
       "768   2.276339  2.276535   2.304269  2.632967 -0.046750 -0.085074 -13.397695   \n",
       "\n",
       "     accoci        ps  shareswa  ...  revenueusd   revenue  divyield  \\\n",
       "0       NaN  0.294485 -2.947541  ...   -1.689038 -1.689038       NaN   \n",
       "1       NaN  0.232390 -2.947541  ...   -1.689038 -1.689038       NaN   \n",
       "2       NaN  0.015059 -2.947541  ...   -1.689038 -1.689038       NaN   \n",
       "3       NaN  0.046107 -2.947541  ...   -1.689038 -1.689038       NaN   \n",
       "4       NaN  0.077154 -2.947541  ...   -1.689038 -1.689038       NaN   \n",
       "..      ...       ...       ...  ...         ...       ...       ...   \n",
       "764     NaN  1.287999  0.518039  ...    0.872251  0.872251       NaN   \n",
       "765     NaN  1.815803  0.518039  ...    0.872251  0.872251       NaN   \n",
       "766     NaN  1.971040  0.518039  ...    0.872251  0.872251       NaN   \n",
       "767     NaN  1.971040  0.518039  ...    0.872251  0.872251       NaN   \n",
       "768     NaN  2.095229  1.150426  ...    5.812435  5.812435       NaN   \n",
       "\n",
       "         sgna       cor  receivables        gp  taxliabilities    invcap  \\\n",
       "0   -1.737656 -1.433170    -0.727768 -1.782124       -1.273314 -1.749773   \n",
       "1   -1.737656 -1.433170    -0.727768 -1.782124       -1.273314 -1.749773   \n",
       "2   -1.737656 -1.433170    -0.727768 -1.782124       -1.273314 -1.749773   \n",
       "3   -1.737656 -1.433170    -0.727768 -1.782124       -1.273314 -1.749773   \n",
       "4   -1.737656 -1.433170    -0.727768 -1.782124       -1.273314 -1.749773   \n",
       "..        ...       ...          ...       ...             ...       ...   \n",
       "764  0.911815  0.912132     0.802412  0.844046        0.722499 -0.429552   \n",
       "765  0.911815  0.912132     0.802412  0.844046        0.722499 -0.429552   \n",
       "766  0.911815  0.912132     0.802412  0.844046        0.722499 -0.429552   \n",
       "767  0.911815  0.912132     0.802412  0.844046        0.722499 -0.429552   \n",
       "768  3.753872  2.572342     8.763506  7.179067        0.155970  6.630790   \n",
       "\n",
       "     currentratio  \n",
       "0        1.509293  \n",
       "1        1.509293  \n",
       "2        1.509293  \n",
       "3        1.509293  \n",
       "4        1.509293  \n",
       "..            ...  \n",
       "764     -0.847556  \n",
       "765     -0.847556  \n",
       "766     -0.847556  \n",
       "767     -0.847556  \n",
       "768      1.131844  \n",
       "\n",
       "[769 rows x 52 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_concat[pipeline._feature_cols] - stats.loc['mean', :]) / stats.loc['std', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3482dc2-524b-4418-b878-16ed9659d08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accoci</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncfdiv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investmentsnc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dps</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debtc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inventory</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>divyield</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean  std\n",
       "accoci          0.0  0.0\n",
       "ncfdiv          0.0  0.0\n",
       "investmentsnc   0.0  0.0\n",
       "dps             0.0  0.0\n",
       "debtc           0.0  0.0\n",
       "inventory       0.0  0.0\n",
       "divyield        0.0  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats['std'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8bca1-8809-40c5-bf76-a1e34482dc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c228741-88f8-4d19-9bc9-0f17fa22efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "afdc6c32-6545-4443-8a27-f2c79933c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'adj_close', 'ev', 'marketcap', 'pb', 'pe', 'evebit',\n",
       "       'retearn', 'accoci', 'ps', 'shareswa', 'de', 'taxassets', 'ncfdiv',\n",
       "       'shareswadil', 'sharesbas', 'debt', 'ps1', 'evebitda', 'bvps',\n",
       "       'ppnenet', 'investmentsnc', 'equity', 'sps', 'rnd', 'debtusd',\n",
       "       'equityusd', 'payables', 'assets', 'liabilities', 'assetsnc', 'depamor',\n",
       "       'tangibles', 'debtnc', 'dps', 'liabilitiesnc', 'debtc', 'tbvps',\n",
       "       'intangibles', 'opex', 'sbcomp', 'grossmargin', 'inventory',\n",
       "       'revenueusd', 'revenue', 'divyield', 'sgna', 'cor', 'receivables', 'gp',\n",
       "       'taxliabilities', 'invcap', 'currentratio', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline._df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "55f6e2ff-63c5-4398-b9dc-b25d7869c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline._df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bba2d500-9fd9-421e-94ce-a0eebb8c8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = get_period_data(pipeline._df, pipeline.train_periods)\n",
    "train_xy_arrs = pipeline.get_xy_arr(train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bc513c8c-781f-40cd-b23b-9ebffca1bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = {\"x\": [], \"y\": [], \"N\": 0}\n",
    "for train_df in train_dfs:\n",
    "    N = train_df.shape[0]\n",
    "    step = max_overlap\n",
    "    if N >= model_seq_len:\n",
    "        for i in range((N - model_seq_len) // (model_seq_len - max_overlap)):\n",
    "            train_arrays[\"x\"].append(train_df[pipeline._feature_cols].iloc[(N - (i * (model_seq_len - max_overlap) + model_seq_len)):(N - i * (model_seq_len - max_overlap))].values)\n",
    "            train_arrays[\"y\"].append([train_df[\"target\"].iloc[(N - i * (model_seq_len - max_overlap)) - 1]])\n",
    "            train_arrays[\"N\"] += 1\n",
    "train_arrays[\"x\"] = np.array(train_arrays['x'][::-1])\n",
    "train_arrays[\"y\"] = np.array(train_arrays['y'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9d6c9b78-d5df-4771-b895-966bf0fdfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_distance = int(np.ceil(model_seq_len / (model_seq_len - max_overlap)))\n",
    "fold_size = (train_arrays[\"N\"] - train_val_distance) // cross_validation_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c57af476-6870-4d69-a873-7f13b85f3100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "28cc7f61-3ceb-4c4b-b9d7-3a40b5b35dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1cf947ff-0795-4c09-a9ef-a4701ee48666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cross_validation_folds):\n",
    "    train_end_ind = fold_size * (i + 1)\n",
    "    val_begin_ind = fold_size * (i + 1) + train_val_distance\n",
    "    val_end_ind = val_begin_ind + fold_size\n",
    "    fold_arrs = {\n",
    "        \"train\":{\n",
    "            \"x\": train_arrays[\"x\"][:train_end_ind],\n",
    "            \"y\": train_arrays[\"y\"][:train_end_ind],\n",
    "        },\n",
    "        \"valid\":{\n",
    "            \"x\": train_arrays[\"x\"][val_begin_ind:val_end_ind],\n",
    "            \"y\": train_arrays[\"y\"][val_begin_ind:val_end_ind],\n",
    "        },\n",
    "    }\n",
    "    folds[i] = fold_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47805e0b-b62a-4039-9c01-10c89877fcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2faa807a-d5fa-453c-bd7e-abdb4c1da975",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff = pd.to_datetime(df['date']) - pd.to_datetime(df['date'].shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094206f6-c6c0-446f-8af6-00f5aa9c1d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ev</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>pb</th>\n",
       "      <th>pe</th>\n",
       "      <th>evebit</th>\n",
       "      <th>retearn</th>\n",
       "      <th>accoci</th>\n",
       "      <th>ps</th>\n",
       "      <th>...</th>\n",
       "      <th>revenueusd</th>\n",
       "      <th>revenue</th>\n",
       "      <th>divyield</th>\n",
       "      <th>sgna</th>\n",
       "      <th>cor</th>\n",
       "      <th>receivables</th>\n",
       "      <th>gp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>invcap</th>\n",
       "      <th>currentratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>23.67</td>\n",
       "      <td>4731.0</td>\n",
       "      <td>4939.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>24.61</td>\n",
       "      <td>4927.2</td>\n",
       "      <td>5135.5</td>\n",
       "      <td>23.8</td>\n",
       "      <td>620.7</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>24.24</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>5058.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>611.3</td>\n",
       "      <td>1064.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>22.63</td>\n",
       "      <td>4514.0</td>\n",
       "      <td>4722.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>570.7</td>\n",
       "      <td>990.3</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>24.02</td>\n",
       "      <td>4804.1</td>\n",
       "      <td>5012.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>605.8</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>25.19</td>\n",
       "      <td>5048.2</td>\n",
       "      <td>5256.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>635.3</td>\n",
       "      <td>1107.5</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>26.84</td>\n",
       "      <td>5392.5</td>\n",
       "      <td>5600.8</td>\n",
       "      <td>25.9</td>\n",
       "      <td>676.9</td>\n",
       "      <td>1183.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>26.73</td>\n",
       "      <td>5369.6</td>\n",
       "      <td>5577.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>674.1</td>\n",
       "      <td>1178.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>26.82</td>\n",
       "      <td>5388.4</td>\n",
       "      <td>5596.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>676.4</td>\n",
       "      <td>1182.2</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adj_close      ev  marketcap    pb     pe  evebit  \\\n",
       "1315  2016-01-25      23.67  4731.0     4939.3  22.9  597.0  1038.0   \n",
       "1316  2016-01-22      24.61  4927.2     5135.5  23.8  620.7  1081.0   \n",
       "1317  2016-01-21      24.24  4850.0     5058.3  23.4  611.3  1064.1   \n",
       "1318  2016-01-20      22.63  4514.0     4722.3  21.9  570.7   990.3   \n",
       "1319  2016-01-19      24.02  4804.1     5012.4  23.2  605.8  1054.0   \n",
       "1320  2016-01-15      25.19  5048.2     5256.5  24.3  635.3  1107.5   \n",
       "1321  2016-01-14      26.84  5392.5     5600.8  25.9  676.9  1183.1   \n",
       "1322  2016-01-13      26.73  5369.6     5577.9  25.8  674.1  1178.1   \n",
       "1323  2016-01-12      26.82  5388.4     5596.7  25.9  676.4  1182.2   \n",
       "\n",
       "         retearn  accoci    ps  ...   revenueusd      revenue  divyield  \\\n",
       "1315  25049000.0     0.0  14.0  ...  109706000.0  109706000.0       0.0   \n",
       "1316  25049000.0     0.0  14.5  ...  109706000.0  109706000.0       0.0   \n",
       "1317  25049000.0     0.0  14.3  ...  109706000.0  109706000.0       0.0   \n",
       "1318  25049000.0     0.0  13.4  ...  109706000.0  109706000.0       0.0   \n",
       "1319  25049000.0     0.0  14.2  ...  109706000.0  109706000.0       0.0   \n",
       "1320  25049000.0     0.0  14.9  ...  109706000.0  109706000.0       0.0   \n",
       "1321  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "1322  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "1323  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "\n",
       "            sgna         cor  receivables          gp  taxliabilities  \\\n",
       "1315  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1316  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1317  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1318  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1319  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1320  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1321  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1322  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1323  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "\n",
       "           invcap  currentratio  \n",
       "1315  130095000.0         3.741  \n",
       "1316  130095000.0         3.741  \n",
       "1317  130095000.0         3.741  \n",
       "1318  130095000.0         3.741  \n",
       "1319  130095000.0         3.741  \n",
       "1320  130095000.0         3.741  \n",
       "1321  130095000.0         3.741  \n",
       "1322  130095000.0         3.741  \n",
       "1323  130095000.0         3.741  \n",
       "\n",
       "[9 rows x 53 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1315:1323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c76c032-3b41-43b3-b651-35b40a024eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       31.945\n",
       "1       31.945\n",
       "2       31.945\n",
       "3       31.945\n",
       "4       31.945\n",
       "         ...  \n",
       "1340    11.881\n",
       "1341    11.881\n",
       "1342    11.881\n",
       "1343    11.881\n",
       "1344    11.881\n",
       "Name: ps1, Length: 1345, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ps1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ab223-7772-4bdf-8110-09f1ac9dc041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
