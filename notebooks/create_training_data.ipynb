{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a91596-6193-46a1-b7ed-f2eda9d5a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1f8691-1441-4cfd-ab0f-e2682f4b2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(Path(\".\").absolute().parent.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6a1e47-3860-4bf9-875a-a24415bb1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import model_data as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f6ce3a-7635-4209-9ff7-9c5d33085f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        target: str\n",
      "            target can be \"price\", \"return\" or \"log_return\"\n",
      "        target_type: str\n",
      "            target type can be \"single\" for single point-in-time prediction \n",
      "            or \"sequence\" for sequence prediction (predicts a sequence of target shifted one day into the future)\n",
      "            if single, output y shape is (N, 1)\n",
      "            if sequence, output y shape is (N, model_seq_len, 1)\n",
      "        model_seq_len: int\n",
      "            model sequence length specifies the sequence length of each input sample. \n",
      "            E.g. 30 means using the past 30 days's historical data to predict the next day\n",
      "        max_overlap: int\n",
      "            maximum number of overlapping days between two sequences\n",
      "        train_periods: list(tuple(str, str))\n",
      "            training periods is a list of tuples, each tuple has a start date and an end date. Data from all training periods are put together\n",
      "            Note that training periods will be further divided into time series cross validation\n",
      "        test_periods: list(tuple(str, str))\n",
      "            similar to training periods\n",
      "        cross_validation_folds: int\n",
      "            number of folds for rolling cross validation\n",
      "        data_path: str or pathlib.Path\n",
      "            path to the input data directory. Default: project_root/data/feature_selected\n",
      "        output_path: str or pathlib.Path\n",
      "            root path to store the output data. Default: project_root/data/model_data\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(md.SingleTickerPipeline.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cb7fed-a6f5-4425-9b62-b15ce22f1bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_ticker_pipeline = md.SingleTickerPipeline(\n",
    "    target=\"price\",\n",
    "    target_type=\"single\",\n",
    "    model_seq_len=30,\n",
    "    max_overlap=20,\n",
    "    train_periods=[\n",
    "        (\"2000-01-01\", \"2006-12-31\"),\n",
    "        (\"2009-01-01\", \"2018-12-31\"),\n",
    "    ],\n",
    "    test_periods=[\n",
    "        (\"2007-01-01\", \"2008-12-31\"),\n",
    "        (\"2019-01-01\", \"2021-04-01\"),\n",
    "    ],\n",
    "    cross_validation_folds=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab11293-46f5-43ac-a6a4-e298c752f61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_data:Reading data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/feature_selected/TEAM.csv...\n",
      "INFO:src.model_data:Making training arrays...\n",
      "INFO:src.model_data:  Training has 73 sequences of length 30.\n",
      "INFO:src.model_data:Making 5 validation folds...\n",
      "INFO:src.model_data:  Generating folds with fold_size=11 and distance between train and validation being 3\n",
      "INFO:src.model_data:    Fold 0 shapes:\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 1 shapes:\n",
      "INFO:src.model_data:      x: (22, 30, 52), y: (22, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 2 shapes:\n",
      "INFO:src.model_data:      x: (33, 30, 52), y: (33, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 3 shapes:\n",
      "INFO:src.model_data:      x: (44, 30, 52), y: (44, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:    Fold 4 shapes:\n",
      "INFO:src.model_data:      x: (55, 30, 52), y: (55, 1)\n",
      "INFO:src.model_data:      x: (11, 30, 52), y: (11, 1)\n",
      "INFO:src.model_data:Making testing arrays...\n",
      "INFO:src.model_data:  Training has 537 sequences of length 30.\n",
      "INFO:src.model_data:Saving generated data at /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:src.model_data:  Writing train folds...\n",
      "INFO:src.model_data:  Writing test arrays...\n"
     ]
    }
   ],
   "source": [
    "single_ticker_pipeline.prepare_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48963822-cd45-4cf2-af6a-a5783c6841b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.model_data:Loading generated data from /home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/model_data/TEAM...\n",
      "INFO:src.model_data:  Loading train folds...\n",
      "INFO:src.model_data:  Loading test arrays...\n"
     ]
    }
   ],
   "source": [
    "# If loading existing data:\n",
    "single_ticker_pipeline.load_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3560fa-08d0-4b5f-ba0b-9e2b6080994d",
   "metadata": {},
   "source": [
    "### Train dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3253eadb-5e55-44c0-9872-c4b6e10df33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(22, 30, 52)\",\n",
      "            \"y\": \"(22, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(33, 30, 52)\",\n",
      "            \"y\": \"(33, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(44, 30, 52)\",\n",
      "            \"y\": \"(44, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        }\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"train\": {\n",
      "            \"x\": \"(55, 30, 52)\",\n",
      "            \"y\": \"(55, 1)\"\n",
      "        },\n",
      "        \"valid\": {\n",
      "            \"x\": \"(11, 30, 52)\",\n",
      "            \"y\": \"(11, 1)\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps({i: {s: {k: str(v.shape) for k, v in arr.items()} for s, arr in fold.items()} for i, fold in single_ticker_pipeline._train_out.items()}, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c5e82-7684-4a1d-b1cf-f8226e336cd6",
   "metadata": {},
   "source": [
    "### Test dictionary structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7a171f-0aff-473c-908a-6e5b1973d45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"N\": 537,\n",
      "    \"x\": \"(537, 30, 52)\",\n",
      "    \"y\": \"(537, 1)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps({k: str(v.shape) if hasattr(v, \"shape\") else v for k, v in single_ticker_pipeline._test_out.items()}, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b0962-96d6-48af-9ded-fccfdc9f7676",
   "metadata": {},
   "source": [
    "# Drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b22be205-1303-4861-85b1-2eb106b88d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed539f-4774-4ff2-b177-37598b948551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58ae2517-3f52-44cc-8f23-a695050d8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = Path(\"./create_training_data.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa14cca2-4496-42d8-9d29-806cb1462a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7fc885e4-0473-4671-8ff6-96443438ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(__file__).absolute().parent.parent.joinpath(\"data/feature_selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b333a106-a604-45c1-b6f5-9bfc1b1eca61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rluo/raid/classes/gatech/cs7643/GATech-CS7643-Project-Group/data/feature_selected')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae2dd93-5cfa-4404-aab2-18811dc30ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = list(data_path.glob(\"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbc5d0-9fa4-4790-8569-91d72c64550b",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4de1e901-d29c-43bc-9f7a-563d5acadd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target can be \"price\", \"return\" or \"log_return\"\n",
    "target = \"price\"\n",
    "\n",
    "# target type can be single prediction or sequence prediction\n",
    "target_type = \"sequence\"\n",
    "\n",
    "# model sequence length specifies the sequence length of each input sample. E.g. 30 means using the past 30 days's historical data to predict the next day\n",
    "model_seq_len = 30\n",
    "\n",
    "# maximum number of overlapping days of historical data between two records\n",
    "max_overlap = 20\n",
    "\n",
    "# training periods is a list of tuples, each tuple has a start date and an end date. Data from all training periods are put together\n",
    "# Note that training periods will be further divided into training and valiation, or time series cross validation\n",
    "train_periods = [\n",
    "    (\"2000-01-01\", \"2006-12-31\"),\n",
    "    (\"2010-01-01\", \"2018-12-31\")\n",
    "]\n",
    "\n",
    "# testing periods - similar to training periods\n",
    "test_periods = [\n",
    "    (\"2007-01-01\", \"2009-12-31\"),\n",
    "    (\"2019-01-01\", \"2021-04-01\")\n",
    "]\n",
    "\n",
    "cross_validation_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38ec48-6d84-4249-af02-e0972e260407",
   "metadata": {},
   "source": [
    "## Single Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "988f1883-a10e-4753-80a0-271437658c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__ = \"create_training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2ae030e6-6c90-4da3-846a-06ba0d7d2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class SingleTickerPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target=\"price\",\n",
    "        target_type=\"sequence\",\n",
    "        model_seq_len=30,\n",
    "        max_overlap=20,\n",
    "        train_periods=[\n",
    "            (\"2000-01-01\", \"2006-12-31\"),\n",
    "            (\"2009-01-01\", \"2018-12-31\"),\n",
    "        ],\n",
    "        test_periods=[\n",
    "            (\"2007-01-01\", \"2008-12-31\"),\n",
    "            (\"2019-01-01\", \"2021-04-01\"),\n",
    "        ],\n",
    "        cross_validation_folds=10,\n",
    "        data_path=Path(__file__).absolute().parent.parent.joinpath(\"data/feature_selected\"),\n",
    "        output_path=Path(__file__).absolute().parent.parent.joinpath(\"data/model_data\"),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        target: str\n",
    "            target can be \"price\", \"return\" or \"log_return\"\n",
    "        target_type: str\n",
    "            target type can be \"single\" for single point-in-time prediction \n",
    "            or \"sequence\" for sequence prediction (predicts a sequence of target shifted one day into the future)\n",
    "            if single, output y shape is (N, 1)\n",
    "            if sequence, output y shape is (N, model_seq_len, 1)\n",
    "        model_seq_len: int\n",
    "            model sequence length specifies the sequence length of each input sample. \n",
    "            E.g. 30 means using the past 30 days's historical data to predict the next day\n",
    "        max_overlap: int\n",
    "            maximum number of overlapping days between two sequences\n",
    "        train_periods: list(tuple(str, str))\n",
    "            training periods is a list of tuples, each tuple has a start date and an end date. Data from all training periods are put together\n",
    "            Note that training periods will be further divided into time series cross validation\n",
    "        test_periods: list(tuple(str, str))\n",
    "            similar to training periods\n",
    "        cross_validation_folds: int\n",
    "            number of folds for rolling cross validation\n",
    "        data_path: str or pathlib.Path\n",
    "            path to the input data directory. Default: project_root/data/feature_selected\n",
    "        output_path: str or pathlib.Path\n",
    "            root path to store the output data. Default: project_root/data/model_data\n",
    "        \"\"\"\n",
    "        self.target = target\n",
    "        self.target_type = target_type\n",
    "        self.model_seq_len = model_seq_len\n",
    "        self.max_overlap = max_overlap\n",
    "        self.train_periods = train_periods\n",
    "        self.test_periods = test_periods\n",
    "        self.cross_validation_folds = cross_validation_folds\n",
    "        self.data_path = Path(data_path)\n",
    "        self.output_path = Path(output_path)\n",
    "        \n",
    "        # internal attributes\n",
    "        self._df = None\n",
    "        self._ticker = None\n",
    "        self._feature_cols = None\n",
    "        self._train_out = None\n",
    "        self._test_out = None\n",
    "        self._seq_dist = self.model_seq_len - self.max_overlap\n",
    "        self._save_path = None\n",
    "        \n",
    "    def load_data(self, ticker=None):\n",
    "        ticker = ticker or self._ticker\n",
    "        data_file = self.data_path.joinpath(f\"{ticker}.csv\")\n",
    "        LOG.info(f\"Reading data from {data_file.as_posix()}...\")\n",
    "        df = pd.read_csv(data_file).drop('price', axis=1, errors=\"ignore\").sort_values(\"date\", ascending=True)\n",
    "        if target == \"price\":\n",
    "            df.loc[:, \"target\"] = df['adj_close']\n",
    "        else: \n",
    "            if target == \"return\":\n",
    "                return_col = get_return_col(df, log=False)\n",
    "            if target == \"log_return\":\n",
    "                return_col = get_return_col(df, log=True)\n",
    "            df.loc[:, \"target\"] = df[return_col]\n",
    "            df.drop(['adj_close'])\n",
    "        self._feature_cols = df.drop(['date', 'target'], axis=1).columns.tolist()\n",
    "        \n",
    "        # match the target with data from the previous days\n",
    "        df = pd.concat([df[['target']].iloc[1:, :].reset_index(drop=True), df[self._feature_cols + [\"date\"]].iloc[:-1, :].reset_index(drop=True)], axis=1)\n",
    "        self._df = df\n",
    "\n",
    "\n",
    "        \n",
    "    def get_xy_arr(self, dfs, seq_dist=None):\n",
    "        seq_dist = seq_dist or self._seq_dist\n",
    "        arrays = {\"x\": [], \"y\": [], \"N\": 0}\n",
    "        for df in dfs:\n",
    "            N = df.shape[0]\n",
    "            if N >= self.model_seq_len:\n",
    "                for i in range((N - self.model_seq_len) // seq_dist):\n",
    "                    arrays[\"x\"].append(df[self._feature_cols].iloc[(N - (i * seq_dist + self.model_seq_len)):(N - i * seq_dist)].values)\n",
    "                    if self.target_type == \"sequence\":\n",
    "                        arrays[\"y\"].append(df[[\"target\"]].iloc[(N - (i * seq_dist + self.model_seq_len)):(N - i * seq_dist)].values)\n",
    "                    elif self.target_type == \"single\":\n",
    "                        arrays[\"y\"].append([df[\"target\"].iloc[(N - i * seq_dist) - 1]])\n",
    "                    else:\n",
    "                        raise KeyError(\"Unknown target_type: target_type must be one of 'sequence' or 'single'!\")\n",
    "                    arrays[\"N\"] += 1\n",
    "        arrays[\"x\"] = np.array(arrays['x'][::-1])\n",
    "        arrays[\"y\"] = np.array(arrays['y'][::-1])\n",
    "        return arrays\n",
    "\n",
    "    def create_train_array(self):\n",
    "        LOG.info(\"Making training arrays...\")\n",
    "        train_dfs = get_period_data(self._df, self.train_periods)\n",
    "        train_xy_arrs = self.get_xy_arr(train_dfs)\n",
    "        LOG.info(f\"  Training has {train_xy_arrs['N']} sequences of length {self.model_seq_len}.\")\n",
    "        \n",
    "        LOG.info(f\"Making {self.cross_validation_folds} validation folds...\")\n",
    "        train_val_distance = int(np.ceil(self.model_seq_len / self._seq_dist))\n",
    "        fold_size = (train_xy_arrs[\"N\"] - train_val_distance) // self.cross_validation_folds\n",
    "        \n",
    "        LOG.info(f\"  Generating folds with fold_size={fold_size} and distance between train and validation being {train_val_distance}\")\n",
    "        folds = {}\n",
    "        for i in range(cross_validation_folds):\n",
    "            train_end_ind = fold_size * (i + 1)\n",
    "            val_begin_ind = fold_size * (i + 1) + train_val_distance\n",
    "            val_end_ind = val_begin_ind + fold_size\n",
    "            fold_arrs = {\n",
    "                \"train\":{\n",
    "                    \"x\": train_xy_arrs[\"x\"][:train_end_ind],\n",
    "                    \"y\": train_xy_arrs[\"y\"][:train_end_ind],\n",
    "                },\n",
    "                \"valid\":{\n",
    "                    \"x\": train_xy_arrs[\"x\"][val_begin_ind:val_end_ind],\n",
    "                    \"y\": train_xy_arrs[\"y\"][val_begin_ind:val_end_ind],\n",
    "                },\n",
    "            }\n",
    "            folds[i] = fold_arrs\n",
    "            LOG.info(f\"    Fold {i} shapes:\")\n",
    "            for sample in fold_arrs:\n",
    "                LOG.info(f\"      x: {fold_arrs[sample]['x'].shape}, y: {fold_arrs[sample]['y'].shape}\")\n",
    "        \n",
    "        self._train_out = folds\n",
    "        \n",
    "    def create_test_array(self):\n",
    "        LOG.info(\"Making testing arrays...\")\n",
    "        test_dfs = get_period_data(self._df, self.test_periods)\n",
    "        test_xy_arrs = self.get_xy_arr(test_dfs, seq_dist=1)\n",
    "        self._test_out = test_xy_arrs\n",
    "    \n",
    "    def create_arrays(self):\n",
    "        self.create_train_array()\n",
    "        self.create_test_array()\n",
    "        self._save_path = self.output_path.joinpath(self._ticker)\n",
    "        LOG.info(f\"Saving generated data at {self._save_path.as_posix()}...\")\n",
    "        if not self._save_path.exists():\n",
    "            LOG.info(f\"  Directory doesn't exist, making directory...\")\n",
    "            self._save_path.mkdir(parents=True)\n",
    "        LOG.info(\"  Writing train folds...\")\n",
    "        write_pickle_file(self._train_out, self._save_path.joinpath(\"train.pkl\"))\n",
    "        LOG.info(\"  Writing test arrays...\")\n",
    "        write_pickle_file(self._test_out, self._save_path.joinpath(\"test.pkl\"))\n",
    "        \n",
    "    def prepare_data(self, ticker):\n",
    "        self._ticker = ticker\n",
    "        self.load_data()\n",
    "        self.create_arrays()\n",
    "        \n",
    "        \n",
    "def get_return_col(df, log=False):\n",
    "    price_rat = df['adj_close'] / df['adj_close'].shift(-1)\n",
    "    if log:\n",
    "        return_col_name = \"log_return\"\n",
    "        return_col_value = np.log(price_rat)\n",
    "    else:\n",
    "        return_col_name = \"return\"\n",
    "        return_col_value = price_rat - 1\n",
    "    df.loc[:, return_col_name] = return_col_value\n",
    "    return return_col_name\n",
    "\n",
    "\n",
    "def get_period_data(df, periods, date_col=\"date\"):\n",
    "    dfs_by_period = [df[pd.to_datetime(df[date_col]).between(pd.to_datetime(period[0]), pd.to_datetime(period[1]))].sort_values(date_col, ascending=True) for period in periods]\n",
    "    return dfs_by_period\n",
    "\n",
    "\n",
    "def write_pickle_file(obj, file):\n",
    "    with Path(file).open('wb') as pkl_file:\n",
    "        pickle.dump(obj, pkl_file, protocol=4)\n",
    "\n",
    "\n",
    "def load_pickle_file(file):\n",
    "    with Path(file).open('rb') as pkl_file:\n",
    "        obj = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "fcb04861-d3ae-4a57-aa87-d796a8c74e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = SingleTickerPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "dc06341e-e17e-4494-bad8-57a7fac6f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.prepare_data(\"TEAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "afdc6c32-6545-4443-8a27-f2c79933c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'adj_close', 'ev', 'marketcap', 'pb', 'pe', 'evebit',\n",
       "       'retearn', 'accoci', 'ps', 'shareswa', 'de', 'taxassets', 'ncfdiv',\n",
       "       'shareswadil', 'sharesbas', 'debt', 'ps1', 'evebitda', 'bvps',\n",
       "       'ppnenet', 'investmentsnc', 'equity', 'sps', 'rnd', 'debtusd',\n",
       "       'equityusd', 'payables', 'assets', 'liabilities', 'assetsnc', 'depamor',\n",
       "       'tangibles', 'debtnc', 'dps', 'liabilitiesnc', 'debtc', 'tbvps',\n",
       "       'intangibles', 'opex', 'sbcomp', 'grossmargin', 'inventory',\n",
       "       'revenueusd', 'revenue', 'divyield', 'sgna', 'cor', 'receivables', 'gp',\n",
       "       'taxliabilities', 'invcap', 'currentratio', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline._df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "55f6e2ff-63c5-4398-b9dc-b25d7869c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline._df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bba2d500-9fd9-421e-94ce-a0eebb8c8941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = get_period_data(pipeline._df, pipeline.train_periods)\n",
    "train_xy_arrs = pipeline.get_xy_arr(train_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bc513c8c-781f-40cd-b23b-9ebffca1bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_arrays = {\"x\": [], \"y\": [], \"N\": 0}\n",
    "for train_df in train_dfs:\n",
    "    N = train_df.shape[0]\n",
    "    step = max_overlap\n",
    "    if N >= model_seq_len:\n",
    "        for i in range((N - model_seq_len) // (model_seq_len - max_overlap)):\n",
    "            train_arrays[\"x\"].append(train_df[pipeline._feature_cols].iloc[(N - (i * (model_seq_len - max_overlap) + model_seq_len)):(N - i * (model_seq_len - max_overlap))].values)\n",
    "            train_arrays[\"y\"].append([train_df[\"target\"].iloc[(N - i * (model_seq_len - max_overlap)) - 1]])\n",
    "            train_arrays[\"N\"] += 1\n",
    "train_arrays[\"x\"] = np.array(train_arrays['x'][::-1])\n",
    "train_arrays[\"y\"] = np.array(train_arrays['y'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9d6c9b78-d5df-4771-b895-966bf0fdfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_distance = int(np.ceil(model_seq_len / (model_seq_len - max_overlap)))\n",
    "fold_size = (train_arrays[\"N\"] - train_val_distance) // cross_validation_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "c57af476-6870-4d69-a873-7f13b85f3100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "28cc7f61-3ceb-4c4b-b9d7-3a40b5b35dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1cf947ff-0795-4c09-a9ef-a4701ee48666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(cross_validation_folds):\n",
    "    train_end_ind = fold_size * (i + 1)\n",
    "    val_begin_ind = fold_size * (i + 1) + train_val_distance\n",
    "    val_end_ind = val_begin_ind + fold_size\n",
    "    fold_arrs = {\n",
    "        \"train\":{\n",
    "            \"x\": train_arrays[\"x\"][:train_end_ind],\n",
    "            \"y\": train_arrays[\"y\"][:train_end_ind],\n",
    "        },\n",
    "        \"valid\":{\n",
    "            \"x\": train_arrays[\"x\"][val_begin_ind:val_end_ind],\n",
    "            \"y\": train_arrays[\"y\"][val_begin_ind:val_end_ind],\n",
    "        },\n",
    "    }\n",
    "    folds[i] = fold_arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47805e0b-b62a-4039-9c01-10c89877fcc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2faa807a-d5fa-453c-bd7e-abdb4c1da975",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff = pd.to_datetime(df['date']) - pd.to_datetime(df['date'].shift(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094206f6-c6c0-446f-8af6-00f5aa9c1d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>ev</th>\n",
       "      <th>marketcap</th>\n",
       "      <th>pb</th>\n",
       "      <th>pe</th>\n",
       "      <th>evebit</th>\n",
       "      <th>retearn</th>\n",
       "      <th>accoci</th>\n",
       "      <th>ps</th>\n",
       "      <th>...</th>\n",
       "      <th>revenueusd</th>\n",
       "      <th>revenue</th>\n",
       "      <th>divyield</th>\n",
       "      <th>sgna</th>\n",
       "      <th>cor</th>\n",
       "      <th>receivables</th>\n",
       "      <th>gp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>invcap</th>\n",
       "      <th>currentratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>2016-01-25</td>\n",
       "      <td>23.67</td>\n",
       "      <td>4731.0</td>\n",
       "      <td>4939.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>2016-01-22</td>\n",
       "      <td>24.61</td>\n",
       "      <td>4927.2</td>\n",
       "      <td>5135.5</td>\n",
       "      <td>23.8</td>\n",
       "      <td>620.7</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>2016-01-21</td>\n",
       "      <td>24.24</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>5058.3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>611.3</td>\n",
       "      <td>1064.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>2016-01-20</td>\n",
       "      <td>22.63</td>\n",
       "      <td>4514.0</td>\n",
       "      <td>4722.3</td>\n",
       "      <td>21.9</td>\n",
       "      <td>570.7</td>\n",
       "      <td>990.3</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>2016-01-19</td>\n",
       "      <td>24.02</td>\n",
       "      <td>4804.1</td>\n",
       "      <td>5012.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>605.8</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>25.19</td>\n",
       "      <td>5048.2</td>\n",
       "      <td>5256.5</td>\n",
       "      <td>24.3</td>\n",
       "      <td>635.3</td>\n",
       "      <td>1107.5</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>26.84</td>\n",
       "      <td>5392.5</td>\n",
       "      <td>5600.8</td>\n",
       "      <td>25.9</td>\n",
       "      <td>676.9</td>\n",
       "      <td>1183.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>26.73</td>\n",
       "      <td>5369.6</td>\n",
       "      <td>5577.9</td>\n",
       "      <td>25.8</td>\n",
       "      <td>674.1</td>\n",
       "      <td>1178.1</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>26.82</td>\n",
       "      <td>5388.4</td>\n",
       "      <td>5596.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>676.4</td>\n",
       "      <td>1182.2</td>\n",
       "      <td>25049000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>109706000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40020000.0</td>\n",
       "      <td>18473000.0</td>\n",
       "      <td>18273000.0</td>\n",
       "      <td>91233000.0</td>\n",
       "      <td>5584000.0</td>\n",
       "      <td>130095000.0</td>\n",
       "      <td>3.741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  adj_close      ev  marketcap    pb     pe  evebit  \\\n",
       "1315  2016-01-25      23.67  4731.0     4939.3  22.9  597.0  1038.0   \n",
       "1316  2016-01-22      24.61  4927.2     5135.5  23.8  620.7  1081.0   \n",
       "1317  2016-01-21      24.24  4850.0     5058.3  23.4  611.3  1064.1   \n",
       "1318  2016-01-20      22.63  4514.0     4722.3  21.9  570.7   990.3   \n",
       "1319  2016-01-19      24.02  4804.1     5012.4  23.2  605.8  1054.0   \n",
       "1320  2016-01-15      25.19  5048.2     5256.5  24.3  635.3  1107.5   \n",
       "1321  2016-01-14      26.84  5392.5     5600.8  25.9  676.9  1183.1   \n",
       "1322  2016-01-13      26.73  5369.6     5577.9  25.8  674.1  1178.1   \n",
       "1323  2016-01-12      26.82  5388.4     5596.7  25.9  676.4  1182.2   \n",
       "\n",
       "         retearn  accoci    ps  ...   revenueusd      revenue  divyield  \\\n",
       "1315  25049000.0     0.0  14.0  ...  109706000.0  109706000.0       0.0   \n",
       "1316  25049000.0     0.0  14.5  ...  109706000.0  109706000.0       0.0   \n",
       "1317  25049000.0     0.0  14.3  ...  109706000.0  109706000.0       0.0   \n",
       "1318  25049000.0     0.0  13.4  ...  109706000.0  109706000.0       0.0   \n",
       "1319  25049000.0     0.0  14.2  ...  109706000.0  109706000.0       0.0   \n",
       "1320  25049000.0     0.0  14.9  ...  109706000.0  109706000.0       0.0   \n",
       "1321  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "1322  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "1323  25049000.0     0.0  15.8  ...  109706000.0  109706000.0       0.0   \n",
       "\n",
       "            sgna         cor  receivables          gp  taxliabilities  \\\n",
       "1315  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1316  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1317  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1318  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1319  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1320  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1321  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1322  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "1323  40020000.0  18473000.0   18273000.0  91233000.0       5584000.0   \n",
       "\n",
       "           invcap  currentratio  \n",
       "1315  130095000.0         3.741  \n",
       "1316  130095000.0         3.741  \n",
       "1317  130095000.0         3.741  \n",
       "1318  130095000.0         3.741  \n",
       "1319  130095000.0         3.741  \n",
       "1320  130095000.0         3.741  \n",
       "1321  130095000.0         3.741  \n",
       "1322  130095000.0         3.741  \n",
       "1323  130095000.0         3.741  \n",
       "\n",
       "[9 rows x 53 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1315:1323]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c76c032-3b41-43b3-b651-35b40a024eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       31.945\n",
       "1       31.945\n",
       "2       31.945\n",
       "3       31.945\n",
       "4       31.945\n",
       "         ...  \n",
       "1340    11.881\n",
       "1341    11.881\n",
       "1342    11.881\n",
       "1343    11.881\n",
       "1344    11.881\n",
       "Name: ps1, Length: 1345, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ps1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ab223-7772-4bdf-8110-09f1ac9dc041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
